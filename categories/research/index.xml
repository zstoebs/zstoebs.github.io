<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <docs>https://blogs.law.harvard.edu/tech/rss</docs>
    <title>research on Zach Stoebner | ml • neuro • kū</title>
    <link>/categories/research/</link>
    <description>Recent content in research on Zach Stoebner | ml • neuro • kū</description>
    <image>
      <title>research on Zach Stoebner | ml • neuro • kū</title>
      <link>/categories/research/</link>
      <url>https://source.unsplash.com/collection/983219/2000x1322</url>
    </image>
    <ttl>1440</ttl>
    <generator>After Dark 9.2.3 (Hugo 0.81.0)</generator>
    <language>en-US</language>
    <copyright>Copyright &amp;copy; Zachary Stoebner. Licensed under CC-BY-ND-4.0.</copyright>
    <lastBuildDate>Sun, 14 Aug 2022 02:15:31 UT</lastBuildDate>
    <atom:link href="/categories/research/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>segmentation of kidney stones in endoscopic video feeds</title>
      <link>/projects/stone-anno/</link>
      <pubDate>Mon, 08 Nov 2021 02:39:01 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/projects/stone-anno/</guid>
      <description>StoneAnno is my first published first-authorship paper, presenting at SPIE 2022. With the long-term goal of fully-automated robotic endoscopic surgery, we built a dataset of endoscopic kidney stone removal videos and investigated U-Net, U-Net&#43;&#43;, and DenseNet for the segmentation task. We found a U-Net&#43;&#43; model that consistently achieves &amp;gt;0.9 Dice score, with low loss, and produces realistic, convincing segmentations. Moving forward, I am implementing our model on hardware for deployment in ORs, as a part of my master&amp;rsquo;s thesis, and I helped Dr. Kavoussi submit an R21 grant in October 2021.</description>
      <category domain="/categories/research">Research</category>
      <content:encoded><![CDATA[tl;dr StoneAnno is my first published first-authorship paper, presenting at SPIE 2022. My advisor, Prof. Ipek Oguz, connected me and my friend, David Lu, with Dr. Nick Kavoussi at VUMC who wanted to bring surgical endoscopy out of the dark ages. With the long-term goal of fully-automated robotic endoscopic surgery, we built a dataset of endoscopic kidney stone removal videos and investigated U-Net, U-Net&#43;&#43;, and DenseNet for the segmentation task. We found a U-Net&#43;&#43; model that consistently achieves &amp;gt;0.9 Dice score, with low loss, and produces realistic, convincing segmentations. Moving forward, I am implementing our model on hardware for deployment in ORs, as a part of my master&amp;rsquo;s thesis, and I helped Dr. Kavoussi submit an R21 grant in October 2021. In the early stages of the project, we were also accepted for a poster presentation at the 2021 Engineering &amp;amp; Urology Society annual meeting.
Citation Zachary A. Stoebner, Daiwei Lu, Seok Hee Hong, Nicholas L. Kavoussi, and Ipek Oguz &amp;ldquo;Segmentation of kidney stones in endoscopic video feeds&amp;rdquo;, Proc. SPIE 12032, Medical Imaging 2022: Image Processing, 120323G (4 April 2022); https://doi.org/10.1117/12.2613274
[SPIE] [arXiv]
Abstract Image segmentation has been increasingly applied in medical settings as recent developments have skyrocketed the potential applications of deep learning. Urology, specifically, is one field of medicine that is primed for the adoption of a real-time image segmentation system with the long-term aim of automating endoscopic stone treatment. In this project, we explored supervised deep learning models to annotate kidney stones in surgical endoscopic video feeds. In this paper, we describe how we built a dataset from the raw videos and how we developed a pipeline to automate as much of the process as possible. For the segmentation task, we adapted and analyzed three baseline deep learning models – U-Net, U-Net&#43;&#43;, and DenseNet – to predict annotations on the frames of the endoscopic videos with the highest accuracy above 90%. To show clinical potential for real-time use, we also confirmed that our best trained model can accurately annotate new videos at 30 frames per second. Our results demonstrate that the proposed method justifies continued development and study of image segmentation to annotate ureteroscopic video feeds.
Results  Figure 1. A comparison of vanilla (V) and pretrained (P) model training accuracies. Vanilla U-Net and U-Net&#43;&#43; start at a lower accuracy of approximately 0.75 Dice and gradually converge to a Dice score of approximately 0.88. ImageNet- pretrained U-Net and U-Net&#43;&#43; start at approximately 0.85 Dice, the convergence of the vanilla versions, and converge to about 0.91 and 0.92 Dice, respectively.    Figure 2. A comparison of our best models’ Dice score (left) and BCE loss (right) from training. Note that the y-axis is scaled to the range of values. DenseNet had the highest and most variant BCE loss, yet its outlier values are relatively low compared to those in other binary classification tasks as BCE does not have an upper bound.    Figure 3. Sample frame from the side-by-side video reconstruction of the input, ground truth, automated prediction with U-Net&#43;&#43;, and heat map (left to right). The heat map is the raw probability output per pixel whereas the predicted segmentation is the pixels with probabilities ≥ 0.5. The model was able to compute this output at 30 FPS.     Table 1. Summary of the statistics gathered for each model. Non-parenthetical values are the average scores from all frames in the test set. The reported value in parentheses is the maximum value recorded from each baseline’s validation during training. The highest performances between models for each metric are denoted in bold. U-Net&#43;&#43; claimed the highest scores in each metric on the test set. U-Net had the same test Dice score as U-Net&#43;&#43; but lower scores in all other metrics. DenseNet had relatively poor performance for all metrics. Only the ROC curves from test set performances are included.    Video 1. Example performance video of our best U-Net&#43;&#43; video on new data, not in train / val / test sets. The video shows a saline treatment and a stone that is being broken down with a laser. Detritus from the laser treatment is collecting to the left of the stone. This video is a typical example of what the model would see in a practical setting.   Future To deploy our high-performing model for surgical use in operating rooms, we will extend our video processing script to receive “in-step” frame-by-frame video input from a video capture card connected via DVI/HDMI to the endoscopic hardware. Then, we will output the side-by-side frames, as in Figure 5, to an adjacent monitor to assist physicians in surgery. Developing such a system will allow us to investigate further goals, such as monocular depth prediction which might prove critical in automation.18
We will also investigate the application of temporal models for our system. Incorporating information from previous frames might allow for more consistent prediction between subsequent frames. In addition, such models account for memory of data from previous frames without the overhead of additional input dimensions suffered by our current fully convolutional models. For this task, we will incorporate self-attention modules into our U-Net and U-Net&#43;&#43; architectures, which has been shown to increase performance in video segmentation.19
In practice, the problem domain also requires the segmentation of kidney stones after they have been surgically broken down into smaller pieces. The current dataset has been developed to support the segmentation of only whole kidney stones. Further development will include expansion of another section of the dataset where, as a surgeon breaks stones apart, the debris fragments will still be labeled by our model. In Figure 5, our model already segments clumps of debris; however, our future goal is finer granularity via an instance segmentation method.20
Additionally, we plan to incorporate multi-class segmentation to also identify, for example, healthy vs. un- healthy tissue. Since the task performs well on stone segmentation, we hypothesize that we can utilize the same underlying architectures to adapt to multi-class segmentation and that the model will perform similarly well, with relatively few manually annotated examples.21
References [1] Minaee, S., Boykov, Y. Y., Porikli, F., Plaza, A. J., Kehtarnavaz, N., and Terzopoulos, D., “Image Seg- mentation Using Deep Learning: A Survey,” IEEE Transactions on Pattern Analysis and Machine Intelli- gence 8828(c), 1–20 (2021).
[2] Zaitoun, N. M. and Aqel, M. J., “Survey on Image Segmentation Techniques,” in [Procedia Computer Science], 65, 797–806, Elsevier (jan 2015).
[3] Badrinarayanan, V., Kendall, A., and Cipolla, R., “SegNet: A Deep Convolutional Encoder-Decoder Ar- chitecture for Image Segmentation,” IEEE Transactions on Pattern Analysis and Machine Intelligence 39, 2481–2495 (dec 2017).
[4] Ronneberger, O., Fischer, P., and Brox, T., “U-net: Convolutional networks for biomedical image segmen- tation,” in [Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)], 9351, 234–241, Springer International Publishing, Cham (2015).
[5] Chen, L. C., Papandreou, G., Schroff, F., and Adam, H., “Rethinking atrous convolution for semantic image segmentation,” (jun 2017).
[6] Simonyan, K. and Zisserman, A., “Very deep convolutional networks for large-scale image recognition,” in [3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings], International Conference on Learning Representations, ICLR (sep 2015).
[7] Zhou, Z., Siddiquee, M. M. R., Tajbakhsh, N., Liang, J., Rahman Siddiquee, M. M., Tajbakhsh, N., and Liang, J., “UNet&#43;&#43;: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation,” IEEE Transactions on Medical Imaging 39(6), 1856–1867 (2020).
[8] Safi, S., Thiessen, T., and Schmailzl, K. J., “Acceptance and Resistance of New Digital Technologies in Medicine: Qualitative Study,” JMIR Res Protoc 7, e11072 (Dec 2018).
[9] Nithya, A., Appathurai, A., Venkatadri, N., Ramji, D. R., and Anna Palagan, C., “Kidney disease detection and segmentation using artificial neural network and multi-kernel k-means clustering for ultrasound images,” Measurement: Journal of the International Measurement Confederation 149, 106952 (jan 2020).
[10] Viswanath, K. and Gunasundari, R., “Design and analysis performance of kidney stone detection from ultrasound image by level set segmentation and ANN classification,” in [2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)], IEEE (sep 2014).
[11] Jegou, S., Drozdzal, M., Vazquez, D., Romero, A., and Bengio, Y., “The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation,” IEEE CVPR Workshops , 1175–1183 (2017).
[12] Huang, G., Liu, Z., Van Der Maaten, L., and Weinberger, K. Q., “Densely connected convolutional net- works,” IEEE CVPR 2017-Janua, 2261–2269 (2017).
[13] Otsu, N., “A Threshold Selection Method from Gray-level Histograms,” IEEE Transactions on Systems, Man and Cybernetics 9(1), 62–66 (1979).
[14] He, K., Zhang, X., Ren, S., and Sun, J., “Deep residual learning for image recognition,” IEEE CVPR 2016- Decem, 770–778 (2016).
[15] Sørensen, T., “A method of establishing groups of equal amplitude in plant sociology based on similar- ity of species and its application to analyses of the vegetation on danish commons”,” Kongelige Danske Videnskabernes Selskab 5(4), 1–34 (1948).
[16] Iremashvili, V., Li, S., Penniston, K. L., Best, S. L., Hedican, S. P., and Nakada, S. Y., “Role of Residual Fragments on the Risk of Repeat Surgery after Flexible Ureteroscopy and Laser Lithotripsy: Single Center Study,” J Urol 201, 358–363 (02 2019).
[17] Ward, T. M., Mascagni, P., Ban, Y., Rosman, G., Padoy, N., Meireles, O., and Hashimoto, D. A., “Computer vision in surgery,” Surgery 169(5), 1253–1256 (2021).
[18] Fu, H., Gong, M., Wang, C., Batmanghelich, K., and Tao, D., “Deep ordinal regression network for monoc- ular depth estimation,” in [Proceedings of the IEEE conference on computer vision and pattern recognition], 2002–2011 (2018).
[19] Ji, G.-P., Chou, Y.-C., Fan, D.-P., Chen, G., Fu, H., Jha, D., and Shao, L., “Progressively normalized self-attention network for video polyp segmentation,” arXiv preprint arXiv:2105.08468 (2021).
[20] Zhou, Y., Onder, O. F., Dou, Q., Tsougenis, E., Chen, H., and Heng, P.-A., “Cia-net: Robust nuclei instance segmentation with contour-aware information aggregation,” in [International Conference on Information Processing in Medical Imaging], 682–693, Springer (2019).
[21] Kayalibay, B., Jensen, G., and van der Smagt, P., “Cnn-based segmentation of medical imaging data,” arXiv preprint arXiv:1701.03056 (2017).
]]></content:encoded>
    </item>
    <item>
      <title>cortical surface analysis in Huntington&#39;s disease using linear-mixed models</title>
      <link>/projects/cortical-surface-analysis/</link>
      <pubDate>Tue, 14 Sep 2021 15:38:19 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/projects/cortical-surface-analysis/</guid>
      <description>Although it will be published after StoneAnno, this shape analysis is my first completed research project and technically my first first-authorship, submitted to Brain. I wrote code in R and MATLAB to fit LMMs to the cortical data from T1w MRI of HD patients and then performed statistical analyses on the results using SurfStat and random field theory. We found that, with a novel method for measuring gyrification, LGI uniquely detects changes in the insula.</description>
      <category domain="/categories/research">Research</category>
      <content:encoded><![CDATA[tl;dr Although it will be published after StoneAnno, this shape analysis is my first completed research project and technically my first first-authorship, submitted for review. I wrote code in R and MATLAB to fit LMMs to the cortical data from T1w MRI of HD patients and then performed statistical analyses on the results using SurfStat and random field theory. We found that, with a novel method for measuring gyrification, LGI uniquely detects changes in the insula. Of note, I learned that complicated statistical anlayses are uniquely challenging, that I love LMMs and RFT, and that they are too esoteric in the current day &amp;ndash; let&amp;rsquo;s make them more accessible!
Citation The paper is submitted for review. As soon as it&amp;rsquo;s published, I will cite it here. At that time, I expect to release the code as well.
Background LMMs
random field theory
LGI acquisition method
Abstract The striatum has traditionally been the focus of Huntington’s disease research due to the primary insult to this region and its central role in motor symptoms. Beyond the striatum, evidence of cortical alterations caused by Huntington’s disease has surfaced. However, findings are not coherent between studies which have used cortical thickness for Huntington’s disease since it is the well-established cortical metric of interest in other diseases. In this study, we propose a more comprehensive approach to cortical morphology in Huntington’s disease using cortical thickness, sulcal depth, and local gyrification index. Our results show consistency with prior findings in cortical thickness, including its limitations. Our comparison between cortical thickness and local gyrification index underscores the complementary nature of these two measures &amp;ndash; cortical thickness detects changes in the sensorimotor and posterior areas while local gyrification index identifies insular differences. Since local gyrification index and cortical thickness measures detect changes in different regions, the two used in tandem could provide a clinically relevant measure of disease progression. Our findings suggest that differences in insular regions may correspond to earlier neurodegeneration and may provide a complementary cortical measure for detection of subtle early cortical changes due to Huntington’s disease.
Results CT  Fig 1. Omnibus test results for CT showing the regions of significant contrast across all patients compared to controls. P-values were adjusted for FWER using random field theory (\alpha=0.01).   SD  Fig 2. Omnibus test results for SD showing the regions of significant contrast across all patients compared to controls. P-values were adjusted for FWER using random field theory (\alpha=0.01).   LGI  Fig 3. Omnibus test results for LGI showing the regions of significant contrast across all patients compared to controls. P-values were adjusted for FWER using random field theory (\alpha=0.01).   Summary   Table 1. Summary of Regions with Significant Changes Per Feature. The percentage of the structure with significant changes are reported, in terms of the number of vertices. Regions are color-coded according to cooccurrence in the three features. Red = regional changes were detected by all three features. Yellow = regional changes were detected by two of the features. Blue = regional changes were detected by one of the features.   Takeaways A main takeaway was learning the scientific process in action and, most importantly, learning to work with more experienced researchers. I wrote the code and performed all of the analysis that produced our results. However, I did not develop the awesome acquisition method that generated our LGI data nor the statistical theory behind the analysis. Throughout the project, I have relied heavily on the expertise of my co-authors &amp;ndash; all of whom have PhDs whereas I was an undergrad until recently. This first journey in research has been inspiring and indelible. I am beyond grateful for it!
References   Walker FO. Huntington’s disease. Lancet. 2007;369(9557):218-228. doi:10.1016/S0140-6736(07)60111-1
  Long JD, Lee JM, Aylward EH, et al. Genetic Modification of Huntington Disease Acts Early in the Prediagnosis Phase. Am J Hum Genet. 2018;103(3):349-357. doi:10.1016/j.ajhg.2018.07.017
  Paulsen JS, Ph D, Long JD, et al. Prediction of manifest Huntington disease with clinical and imaging measures : A 12-year prospective observational study. 2015;13(12):1193-1201. doi:10.1016/S1474-4422(14)70238-8.Prediction
  Ehrlich ME. Huntington’s Disease and the Striatal Medium Spiny Neuron: Cell- Autonomous and Non-Cell-Autonomous Mechanisms of Disease. Neurotherapeutics. 2012;9(2):270-284. doi:10.1007/s13311-012-0112-2
  Hett K, Johnson H, Coupe P, Paulsen JS, Long JD, Oguz I. Tensor-Based Grading: A Novel Patch-Based Grading Approach for the Analysis of Deformation Fields in Huntington’s Disease. Proc - Int Symp Biomed Imaging. 2020;2020-April:1091-1095. doi:10.1109/ISBI45749.2020.9098692
  Li H, Zhang H, Johnson H, Long J, Paulsen J, Oguz I. Longitudinal subcortical segmentation with deep learning. In: SPIE Medical Imaging 2021: Image Processing. International Society for Optics and Photonics; 2021:115960D. doi:https://doi.org/10.1117/12.2582340
  Li H, Zhang H, Hu D, et al. Generalizing MRI subcortical segmentation to Neurodegeneration. In: MLCN Workshop, MICCAI. Springer, Cham; 2020:139-147. doi:https://doi.org/10.1007/978-3-030-66843-3_14
  Li H, Zhang H, Johnson H, Long J, Paulsen J, Oguz I. MRI Subcortical Segmentation In Neurodegeneration with Cascaded 3D CNNs. In: SPIE Medical Imaging 2021: Image Processing. International Society for Optics and Photonics; 2021:115960W. doi:https://doi.org/10.1117/12.2582005
  Paulsen JS, Nopoulos PC, Aylward E, et al. Striatal and white matter predictors of estimated diagnosis for Huntington disease. Brain Res Bull. 2010;82(3-4):201-207. doi:10.1016/j.brainresbull.2010.04.003
  Hedreen JC, Peyser CE, Folstein SE, Ross CA. Neuronal loss in layers V and VI of cerebral cortex in Huntington’s disease. Neurosci Lett. 1991;133(2):257-261. doi:10.1016/0304-3940(91)90583-F
  Rosas HD, Liu AK, Hersch S, et al. Regional and progressive thinning of the cortical ribbon in Huntington’s disease. Neurology. 2002;58(5):695-701. doi:10.1212/WNL.58.5.695
  Nopoulos PC, Aylward EH, Ross CA, et al. Cerebral cortex structure in prodromal Huntington disease. Neurobiol Dis. 2010;40(3):544-554. doi:10.1016/j.nbd.2010.07.014
  Tabrizi SJ, Langbehn DR, Leavitt BR, et al. Biological and clinical manifestations of Huntington’s disease in the longitudinal TRACK-HD study: cross-sectional analysis of baseline data Sarah. 2013;8(9):791-801. doi:10.1016/S1474-4422(09)70170- X.Biological
  Fischl B, Dale AM. Measuring the thickness of the human cerebral cortex from magnetic resonance images. Proc Natl Acad Sci U S A. 2000;97(20):11050-11055. doi:10.1073/pnas.200033797
  Lyu I, Kang H, Woodward ND, Landman BA. Sulcal depth-based cortical shape analysis in normal healthy control and schizophrenia groups. 2018;1057402(March 2018):1. doi:10.1117/12.2293275
  Lyu I, Kim SH, Girault JB, Gilmore JH, Styner MA. A cortical shape-adaptive approach to local gyrification index. Med Image Anal. 2018;48:244-258. doi:10.1016/j.media.2018.06.009
  Wu D, Faria A V., Younes L, Ross CA, Mori S, Miller MI. Whole-brain segmentation and change-point analysis of anatomical brain mri—application in premanifest huntington’s disease. J Vis Exp. 2018;2018(136):1-9. doi:10.3791/57256
  Tan X, Ross CA, Miller MI, Tang X. CHANGEPOINT ANALYSIS OF PUTAMEN AND THALAMUS SUBREGIONS IN PREMANIFEST HUNTINGTON’S DISEASE. In: 2018 IEEE 15th International Symposium on Biomedical Imaging. ; 2018:531-535. doi:10.1109/ISBI.2018.8363632
  Tang X, Ross CA, Johnson H, et al. Regional subcortical shape analysis in premanifest Huntington’s disease. Hum Brain Mapp. 2019;40(5):1419-1433. doi:10.1002/hbm.24456
  Hong Y, O’Donnell LJ, Savadjiev P, et al. Genetic load determines atrophy in hand cortico-striatal pathways in presymptomatic Huntington’s disease. Hum Brain Mapp. 2018;39(10):3871-3883. doi:10.1002/hbm.24217
  Paulsen JS, Langbehn DR, Stout JC, et al. Detection of Huntington’s disease decades before diagnosis: The Predict-HD study. J Neurol Neurosurg Psychiatry. 2008;79(8):874-880. doi:10.1136/jnnp.2007.128728
  Zhang Y, Long JD, Mills JA, Warner JH, Lu W, Paulsen JS. Indexing disease progression at study entry with individuals at-risk for Huntington disease. Am J Med Genet Part B Neuropsychiatr Genet. 2011;156(7):751-763. doi:10.1002/ajmg.b.31232
  Fischl B. FreeSurfer. Neuroimage. 2012;62(2):774-781. doi:10.1016/j.neuroimage.2012.01.021.FreeSurfer
  Lyu I, Kang H, Woodward ND, Styner MA, Landman BA. Hierarchical spherical deformation for cortical surface registration. Med Image Anal. 2019;57:72-88. doi:10.1016/j.media.2019.06.013
  Parvathaneni P, Bao S, Nath V, et al. Cortical Surface Parcellation Using Spherical Convolutional Neural Networks. Lect Notes Comput Sci (including Subser Lect Notes Artif Intell Lect Notes Bioinformatics). 2019;11766 LNCS:501-509. doi:10.1007/978- 3-030-32248-9_56
  Klein A, Canton TD, Ghosh SS, et al. Open labels: online feedback for a public resource of manually labeled brain images. 16th Annu Meet Organ Hum Brain Mapping. Published online 2010:84358.
  Moorhead TWJ, Harris JM, Stanfield AC, et al. Automated computation of the Gyrification Index in prefrontal lobes: Methods and comparison with manual implementation. Neuroimage. 2006;31(4):1560-1566. doi:10.1016/j.neuroimage.2006.02.025
  Roberts M, Hanaway J, Morest DK. Atlas of the Human Brain in Section. 2nd ed. Lea &amp;amp; Febiger; 1970.
  Lyu I, Kim SH, Woodward ND, Styner MA, Landman BA. TRACE: A Topological Graph Representation for Automatic Sulcal Curve Extraction. IEEE Trans Med Imaging. 2018;37(7):1653-1663. doi:10.1109/TMI.2017.2787589
  Alin A. Multicollinearity. Wiley Interdiscip Rev Comput Stat. 2010;2(3):370-374. doi:10.1002/wics.84
  Verbeke G, Molenberghs G. Linear Mixed Models for Longitudinal Data. Print. Spinger; 2000. https://link.springer.com/chapter/10.1007/978-0-387-22775-7_3
  Worsley KJ, Andermann M, Koulis T, MacDonald D, Evans AC. Detecting changes in nonisotropic images. Hum Brain Mapp. 1999;8(2-3):98-101. doi:10.1002/(SICI)1097- 0193(1999)8:2/3&amp;lt;98::AID-HBM5&amp;gt;3.0.CO;2-F
  Taylor JE, Worsley KJ. Detecting sparse signals in random fields, with an application to brain mapping. J Am Stat Assoc. 2007;102(479):913-928. doi:10.1198/016214507000000815
  Bates D, Mächler M, Bolker BM, Walker SC. Fitting linear mixed-effects models using lme4. J Stat Softw. 2015;67(1). doi:10.18637/jss.v067.i01
  Worsley K, Taylor J, Carbonell F, et al. SurfStat: A Matlab toolbox for the statistical analysis of univariate and multivariate surface and volumetric data using linear mixed effects models and random field theory. Neuroimage. 2009;47:S102. doi:10.1016/s1053-8119(09)70882-1
  Han X, Jovicich J, Salat D, et al. Reliability of MRI-derived measurements of human cerebral cortical thickness: The effects of field strength, scanner upgrade and manufacturer. Neuroimage. 2006;32(1):180-194. doi:10.1016/j.neuroimage.2006.02.051
  Hong EP, MacDonald ME, Wheeler VC, et al. Huntington’s Disease Pathogenesis: Two Sequential Components. J Huntingtons Dis. 2021;10(1):35-51. doi:10.3233/JHD- 200427
  Mangin JF, Rivière D, Duchesnay E, et al. Neocortical morphometry in Huntington’s disease: Indication of the coexistence of abnormal neurodevelopmental and neurodegenerative processes. NeuroImage Clin. 2020;26(February):102211. doi:10.1016/j.nicl.2020.102211
  Scahill RI, Zeun P, Osborne-Crowley K, et al. Biological and clinical characteristics of gene carriers far from predicted onset in the Huntington’s disease Young Adult Study (HD-YAS): a cross-sectional analysis. Lancet Neurol. 2020;19(6):502-512. doi:10.1016/S1474-4422(20)30143-5
  Nopoulos P, Magnotta VA, Ph D, et al. Morphology of the Cerebral Cortex in Preclinical Huntington’s Disease. Am J Psychiatry. 2012;164(September 2007):1428- 1434.
  Brown K. Encyclopedia of Language and Linguistics. Vol 1. Elsevier; 2005.
  ]]></content:encoded>
    </item>
  </channel>
</rss>
