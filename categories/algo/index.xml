<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <docs>https://blogs.law.harvard.edu/tech/rss</docs>
    <title>algo on Zach Stoebner | ml • neuro • kū</title>
    <link>/categories/algo/</link>
    <description>Recent content in algo on Zach Stoebner | ml • neuro • kū</description>
    <image>
      <title>algo on Zach Stoebner | ml • neuro • kū</title>
      <link>/categories/algo/</link>
      <url>https://source.unsplash.com/collection/983219/2000x1322</url>
    </image>
    <ttl>1440</ttl>
    <generator>After Dark 9.2.3 (Hugo 0.81.0)</generator>
    <language>en-US</language>
    <copyright>Copyright &amp;copy; Zachary Stoebner. Licensed under CC-BY-ND-4.0.</copyright>
    <lastBuildDate>Thu, 18 Nov 2021 00:11:04 UT</lastBuildDate>
    <atom:link href="/categories/algo/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>on fiber tracking</title>
      <link>/notes/fiber-tracking/</link>
      <pubDate>Tue, 16 Nov 2021 19:50:49 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/notes/fiber-tracking/</guid>
      <description>After brief description of diffusion tensor images and what information they provide, I discuss an intuitive seed-based line propagation algorithm for computing a tractography map of a neuroimage. The open-source softwares required are 3D Slicer, ITK for C&#43;&#43;, and ITK-SNAP.</description>
      <category domain="/categories/algo">Algo</category>
      <content:encoded><![CDATA[tl;dr After brief description of diffusion tensor images and what information they provide, I discuss an intuitive seed-based line propagation algorithm for computing a tractography map of a neuroimage. A stack of open-source softwares that can be used to implement diffusion tensor tractography are 3D Slicer, ITK for C&#43;&#43;, and ITK-SNAP.
The diffusion tensor image used to generate all figures is publically available as sample data, DTIBrain, via 3D Slicer.
Diffusion Tensor Imaging In a diffusion tensor image (DTI), each voxel is represented by a symmetric tensor with 6 distinct values for the speed of water diffusion, corresponding to the directions from the center of the cubic voxel to each of its faces. Without obstruction, water diffusion is uniform on average in every direction; however, in spaces that alter diffusion, the values in each of these directions are anisotropic. Anisotropic diffusion gives rise to a principal axis of diffusion where some forward and backwards direction have greater values than the rest. Hence, the tensor at the voxel can be visualized as an ellipsoid – the elastic deformation of the cube along the principal axis.
 Sagittal slice of a DTI. 3D Slicer visualizes DTI well with a color orientation scheme, where red means that the principal eigenvector is along the left-right axis, blue means its along the inferior-superior axis, and green means its along the anterior-posterior axis. Intermediate colors means that its along a linear combination of these basis vectors.  Principal Eigenvector The major eigenvector from each diffusion tensor gives the forward direction of the principal axis; the negation of the major eigenvector is the backwards direction. Precomputing this vector image, with one vector at each voxel, yields a map that can be used to route the line propagation algorithm through the brain&amp;rsquo;s tracts. ITK defines a DiffusionTensor3D type that can set as the pixel type for an image; the type also defines a function for computing its eigendecomposition, which can be called when the pixel is accessed by an iterator.
 Sagittal slice of the principal eigenvector image of the DTI. Although it&#39;s noisy, you can see that there is still structure to it that makes sense, i.e., in the corpus callosum and the brain stem.  Fractional Anisotropy Fractional anisotropy (FA) is a scalar value computed from the eigenvalues of the diffusion tensor to quantify the amount of anisotropic diffusion at a voxel in the DTI [3]. A high value insinuates that water diffuses along a single axis, which would correspond to water flowing through a tract. FA for a 3x3 diffusion tensor is computed as follows:
 The formula to compute the scalar FA value, which is solely based on the eigenvalues, where the capped lambda is the mean of the eigenvalues.  When performing tractography, an FA value that is too low implies that water diffusion is largely isotropic, e.g., in grey matter, where there are no tracts. Hence, a minimum FA can be set and used as a stopping condition at a given voxel. ITK&amp;rsquo;s DiffusionTensor3D type defines a function to compute the FA value of the tensor and can be accessed in the same way as the eigendecomposition function.
 Sagittal slice of the FA image of the DTI. The FA image looks strikingly similar to a structural MRI.  Tractography With the directional values, a line can be propagated from a seed voxel along the 3D vector field to reconstruct a 3D tract down the two directions of the principal axis [1]. By propagating a line from a seed, or from many seeds, a rudimentary tractography map of a DTI can be computed. Although line propagation is intuitive and relatively lightweight, it is worth noting that other fiber tracking techniques exist that are both more robust and more intensive [2].
The stopping conditions:
 Current iteration is greater than the max number of iterations chosen by the user. The candidate voxel is outside of the image. The FA at the candidate voxel is below the minimum FA acceptable chosen by the user. The candidate voxel has already been visited.  If no stopping condition was met, then the current voxel was visited, meaning:
 The candidate voxel in the tractography image was set to a non-negative integer. The eigenvector at the candidate voxel was extracted, multiplied by some step size ∆ chosen by the user, added and subtracted from the candidate voxel’s index, and then pushed to the back of the list. Finally, the candidate voxel was popped from the front of the list and the iteration was incremented.  For this task, line propagation can be implemented both iteratively or recursively because it is isomorphic to search algorithms, i.e., breadth-first and depth-first search. Switching between the two is pretty straightforward as the function definitions should not be very different. That said, the recursive algorithm is likely less bloated and more effective computationally, but might be much slower if you&amp;rsquo;re using ITK in Python rather than C&#43;&#43;.
 Views of a tractography image generated by a single seed (top) and multiple seeds from a segmentation image (bottom) for ∆ = 0.9, minimum FA at 0.1, and the maximum number of iterations at 10000. The orientation of the views is given on the top. As expected, multi-seed input generated a much more extensive tractography map.  References [1] Mori S, van Zijl PC. Fiber tracking: principles and strategies - a technical review. NMR Biomed. 2002 Nov-Dec;15(7-8):468-80. https://doi.org/10.1002/nbm.781. PMID: 12489096.
[2] Kleiser R, Staempfli P, Valavanis A, Boesiger P, Kollias S. Impact of fMRI- guided advanced DTI fiber tracking techniques on their clinical applica- tions in patients with brain tumors. Neuroradiology. 2010 Jan;52(1):37-46. https://doi.org/10.1007/s00234-009-0539-2. Epub 2009 May 29. PMID: 19479248.
[3] Basser PJ, Pierpaoli C. Microstructural and physiological features of tissues eluci- dated by quantitative-diffusion-tensor MRI. J Magn Reson B. 1996 Jun;111(3):209- 19. https://doi.org/10.1006/jmrb.1996.0086. PMID: 8661285.
]]></content:encoded>
    </item>
    <item>
      <title>on fast inverse square root</title>
      <link>/notes/fast-inv-sqrt/</link>
      <pubDate>Fri, 02 Jul 2021 03:46:27 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/notes/fast-inv-sqrt/</guid>
      <description>I found it on YouTube and, as my friend Nolan reminded me the other night, this algorithm is not new. The fast inverse square root shook the nerd world with its implementation in Quake III (1999).</description>
      <category domain="/categories/algo">Algo</category>
      <content:encoded><![CDATA[float Q_rsqrt( float number ) { long i; float x2, y; const float threehalfs = 1.5F; x2 = number * 0.5F; y = number; i = * ( long * ) &amp;amp;y; // part 1 i = 0x5f3759df - ( i &amp;gt;&amp;gt; 1 ); // part 2 y = * ( float * ) &amp;amp;i; y = y * ( threehalfs - ( x2 * y * y ) ); // part 3 } I found it on YouTube and, as my friend Nolan reminded me the other night, this algorithm is not new. The fast inverse square root shook the nerd world with its implementation in Quake III (1999).
Notice that it doesn’t use any division operator which is naturally slow on a digital computer; this algorithm speeds up computation of the inverse square root by 3x compared to conventional division and square root operations. The reason for writing it in C is evident in the first part, although these tricks also have analogs in often in other languages such as C&#43;&#43;, Python, etc. and is thus implemented in those languages as well.
Part 1 It uses tricks inherent in the language to cast the address of float (aka a float pointer) to a long pointer. The importance of using a long is evinced in the second part because it allows for quick division by 2. Since standard binary numbers, unlike floats, are not disjointed numbers in base 2, a single right bit shift performs floor halving.
Part 2 This part is the real meat of the trickery in this clever solution. The second half I already explained in the first part but the first half involves rearranging the floating-point formula for a square root division to solve for scalar values. Recall that floating point numbers are comprised of a mantissa and an exponent. The actual digit number can then be composed of a formula of these two parts: (1 &#43; M/2^23)*2^(E - 127) . The exponent is shifted down by 127 in IEEE 754 in order to represent negative values so 2^4 is actually 2^(131-127) where 131 is the number passed in the exponent. Since the mantissa needs to be between 1 and 2 in binary a 1 is fixed as the first digit before the point and the mantissa is divided by 2^23 since the mantissa is represented by 23 bits. Taking the logarithm of the above formula results in: log(1&#43;M/2^23) &#43; log(2^(E - 127)) . The trick to the problem is that log(1&#43;x) ~= x &#43; mu for small numbers (e.g. fractions less than 1). So this simplifies to: M/2^23 &#43; mu &#43; E - 127. Rearranging results in: 1/2^23 * (M &#43; 2^23*E) &#43; mu - 127 which is much more useful because the bit representation of a floating point number (M &#43; 2^23*E) is included. Recall that the binary number for a floating number is 8 bits for E followed by 23 bits for M.
Now that the background is setup, we can continue calculating 1/sqrt(x), or actually 1/sqrt(y) in this case. With the rearrangements above, it becomes much easier to calculate the logarithm of a floating point number. So log(1/sqrt(y)) = log(y^(-1/2)) = -(1/2)*log(y) . So if we want to solve for some G s.t. G = 1/sqrt(y) where log(G) = -(1/2)log(y), we can substitute in the above rearranged logarithm formula for a floating point number and solve for the bit representation for G which ends up as: M_G &#43; 2^23*E_G = (3/2)*2^23*(127 - mu) - (1/2)*(M_y &#43; 2^23*E_y). Hence, the first term is that bizarre hexadecimal number and the dexter term is the subtracted single rightshift to halve the number.
The reason for casting the floating point y to a long should be fairly obvious; we need the hard-coded bit representation of y to be treated as such, not as a floating point number which has different arithmetic operators.
Part 3 The third step is a little esoteric but not as technical as the second step. As with everything on computers, the numbers computed prior to this step are just an approximation. Due to all of the assumptions previously made (e.g. that the halving above isn’t floored for an odd number, that our chosen mu is accurate, etc.), we need to correct by some amount. Cue the Newton Iteration, which computes the error of x from a root for the function y. For this problem, the function is f(y) = 1/y^2 - x which rearranges to y = 1/sqrt(x) when y is a root (e.g. f(y) = 0). We need to compute x_new = x - f(x)/f’(x). Breaking down the derivative of a function: the derivative is described by the tangent line and where it intercepts the x-axis, composing the triangle below:
 A useful reference for a function derivative.  Since the ratio of the shifts times the shift in x equals the shift in y, the shift in x can be solved for as the shift in y divided by the ratio which ends up as: f(x)/f’(x). The actual implementation details of this aren’t made clear by the video, nor is the function derivative computed and I’m quite uncertain about which variable we take the derivative from, x or y. Nonetheless, it results in a static expression without any division operators required.
]]></content:encoded>
    </item>
  </channel>
</rss>
