<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <docs>https://blogs.law.harvard.edu/tech/rss</docs>
    <title>python on Zach Stoebner | ml • neuro • kū</title>
    <link>/tags/python/</link>
    <description>Recent content in python on Zach Stoebner | ml • neuro • kū</description>
    <image>
      <title>python on Zach Stoebner | ml • neuro • kū</title>
      <link>/tags/python/</link>
      <url>https://source.unsplash.com/collection/983219/2000x1322</url>
    </image>
    <ttl>1440</ttl>
    <generator>After Dark 9.2.3 (Hugo 0.102.3)</generator>
    <language>en-US</language>
    <copyright>Copyright &amp;copy; Zachary Stoebner. Licensed under CC-BY-ND-4.0.</copyright>
    <lastBuildDate>Wed, 21 Sep 2022 05:08:23 UT</lastBuildDate>
    <atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>exploring compressed sensing fMRI time series</title>
      <link>/projects/csfmri-ts/</link>
      <pubDate>Tue, 31 May 2022 18:26:14 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/projects/csfmri-ts/</guid>
      <description>An exploration of compressed sensing fMRI time series with 3 different algorithms. Typically, compressed sensing reconstructs a single volume of MRI but fMRI are composed of many volumes; sensing along the time domain could reduce the number of volumes required. Of the 3 algorithms, BSBL-BO performed the best with the error curve elbowing around 30% subsampling.</description>
      <category domain="/categories/course">Course</category>
      <category domain="/categories/solo">Solo</category>
      <content:encoded><![CDATA[ Signal sensing at 30% undersampling using the BSBL-BO algorithm. `$Y_i$` corresponds to time-domain signals whereas `$x_i$` corresponds to frequency-domain signals. tl;dr An exploration of compressed sensing fMRI time series with 3 different algorithms. Typically, compressed sensing reconstructs a single volume of MRI but fMRI are composed of many volumes; sensing along the time domain could reduce the number of volumes required. Of the 3 algorithms, BSBL-BO performed the best with the error curve elbowing around 30% subsampling.
Links repo
report
Abstract Compressed sensing reconstructs signals by solving underdetermined linear systems under the con- ditions that the measurements are sparse in the domain and incoherent [1]. In engineering, if measurements are taken within an appropriate basis satisfying the restricted isometry property, i.e., the Gaussian, Bernoulli, or Fourier bases, then this prior structure makes full signal recovery possible [2].
Compressed sensing is challenging with fMRI because the temporal dynamics of hemodynamic signals are relatively slow compared to other fast-acquisition signals that historically benefit from compressed sensing [3]. Additionally, having fewer samples insinuates a loss of statistical power in subsequent analyses. Thankfully, fMRI signals boast two beneficial characteristics that are promising for compressed sensing: 1. they are linear time-invariant, and 2. they lie within, and can transformed by, a Fourier basis [4].
In medical imaging, it is often assumed that an image is sampled at the Nyquist rate, s.t., enough discrete measurements are taken to reconstruct a continuous whole (M &amp;gt; N) without loss of information. If high-fidelity reconstruction is possible sampling below the Nyquist rate, then MRI modalities would benefit since discerning a signal and quickly turning over an analysis reduces real costs. These potential gains beg the question: if an underdetermined linear system can be solved after sampling below the Nyquist rate, can we collect fewer samples and still recover a high-quality fMRI under a compressed sensing paradigm? The purpose of this project is to explore approaches to compressed sensing that yield meaningful signal recoveries from heavy undersampling.
Results Summary metrics of RMSE (left) and PSNR (right) voxel time series recovery using L1 minimization in a pure convex optimization formulation solved with the ECOS algorithm. Summary metrics of RMSE (left) and PSNR (right) voxel time series recovery using L1 minimization in a pure convex optimization formulation solved with the OWL-QN algorithm. Summary metrics of RMSE (left) and PSNR (right) voxel time series recovery using L1 minimization in a pure convex optimization formulation solved with the BSBL-BO algorithm. References [1] E. J. Candes et al., “Compressive sampling,” in Proceedings of the international congress of mathematicians, vol. 3, pp. 1433–1452, Citeseer, 2006.
[2] D. Angelosante, G. B. Giannakis, and E. Grossi, “Compressed sensing of time-varying signals,” in 2009 16th International Conference on Digital Signal Processing, pp. 1–8, IEEE, 2009.
[3] X. Zong, J. Lee, A. J. Poplawsky, S.-G. Kim, and J. C. Ye, “Compressed sensing fmri using gradient-recalled echo and epi sequences,” NeuroImage, vol. 92, pp. 312–321, 2014.
[4] O. Jeromin, M. S. Pattichis, and V. D. Calhoun, “Optimal compressed sensing reconstructions of fmri using 2d deterministic and stochastic sampling geometries,” Biomedical engineering online, vol. 11, no. 1, pp. 1–36, 2012.
[5] A. Domahidi, E. Chu, and S. Boyd, “ECOS: An SOCP solver for embedded systems,” in European Control Conference (ECC), pp. 3071–3076, 2013.
[6] G. Andrew and J. Gao, “Scalable training of l 1-regularized log-linear models,” in Proceedings of the 24th international conference on Machine learning, pp. 33–40, 2007.
[7] Z. Zhang and B. D. Rao, “Extension of sbl algorithms for the recovery of block sparse signals with intra-block correlation,” IEEE Transactions on Signal Processing, vol. 61, no. 8, pp. 2009– 2015, 2013.
[8] P. Wolfe, “Convergence conditions for ascent methods,” SIAM Review, vol. 11, no. 2, pp. 226– 235, 1969.
[9] H. Park and X. Liu, “Study on compressed sensing of action potential,” arXiv preprint arXiv:2102.00284, 2021.
[10] A. Jalal, M. Arvinte, G. Daras, E. Price, A. G. Dimakis, and J. Tamir, “Robust compressed sensing mri with deep generative priors,” Advances in Neural Information Processing Systems, vol. 34, pp. 14938–14954, 2021.
[11] X. Li, T. Cao, Y. Tong, X. Ma, Z. Niu, and H. Guo, “Deep residual network for highly accel- erated fmri reconstruction using variable density spiral trajectory,” Neurocomputing, vol. 398, pp. 338–346, 2020.
]]></content:encoded>
    </item>
    <item>
      <title>segmentation of kidney stones in endoscopic video feeds</title>
      <link>/projects/stone-anno/</link>
      <pubDate>Mon, 08 Nov 2021 02:39:01 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/projects/stone-anno/</guid>
      <description>StoneAnno is my first published first-authorship paper, presenting at SPIE 2022. With the long-term goal of fully-automated robotic endoscopic surgery, we built a dataset of endoscopic kidney stone removal videos and investigated U-Net, U-Net&#43;&#43;, and DenseNet for the segmentation task. We found a U-Net&#43;&#43; model that consistently achieves &amp;gt;0.9 Dice score, with low loss, and produces realistic, convincing segmentations. Moving forward, I am implementing our model on hardware for deployment in ORs, as a part of my master&amp;rsquo;s thesis, and I helped Dr. Kavoussi submit an R21 grant in October 2021.</description>
      <category domain="/categories/research">Research</category>
      <content:encoded><![CDATA[tl;dr StoneAnno is my first published first-authorship paper, presenting at SPIE 2022. My advisor, Prof. Ipek Oguz, connected me and my friend, David Lu, with Dr. Nick Kavoussi at VUMC who wanted to bring surgical endoscopy out of the dark ages. With the long-term goal of fully-automated robotic endoscopic surgery, we built a dataset of endoscopic kidney stone removal videos and investigated U-Net, U-Net&#43;&#43;, and DenseNet for the segmentation task. We found a U-Net&#43;&#43; model that consistently achieves &amp;gt;0.9 Dice score, with low loss, and produces realistic, convincing segmentations. Moving forward, I am implementing our model on hardware for deployment in ORs, as a part of my master&amp;rsquo;s thesis, and I helped Dr. Kavoussi submit an R21 grant in October 2021. In the early stages of the project, we were also accepted for a poster presentation at the 2021 Engineering &amp;amp; Urology Society annual meeting.
Citation Zachary A. Stoebner, Daiwei Lu, Seok Hee Hong, Nicholas L. Kavoussi, and Ipek Oguz &amp;ldquo;Segmentation of kidney stones in endoscopic video feeds&amp;rdquo;, Proc. SPIE 12032, Medical Imaging 2022: Image Processing, 120323G (4 April 2022); https://doi.org/10.1117/12.2613274
[SPIE] [arXiv]
Abstract Image segmentation has been increasingly applied in medical settings as recent developments have skyrocketed the potential applications of deep learning. Urology, specifically, is one field of medicine that is primed for the adoption of a real-time image segmentation system with the long-term aim of automating endoscopic stone treatment. In this project, we explored supervised deep learning models to annotate kidney stones in surgical endoscopic video feeds. In this paper, we describe how we built a dataset from the raw videos and how we developed a pipeline to automate as much of the process as possible. For the segmentation task, we adapted and analyzed three baseline deep learning models – U-Net, U-Net&#43;&#43;, and DenseNet – to predict annotations on the frames of the endoscopic videos with the highest accuracy above 90%. To show clinical potential for real-time use, we also confirmed that our best trained model can accurately annotate new videos at 30 frames per second. Our results demonstrate that the proposed method justifies continued development and study of image segmentation to annotate ureteroscopic video feeds.
Results Figure 1. A comparison of vanilla (V) and pretrained (P) model training accuracies. Vanilla U-Net and U-Net&#43;&#43; start at a lower accuracy of approximately 0.75 Dice and gradually converge to a Dice score of approximately 0.88. ImageNet- pretrained U-Net and U-Net&#43;&#43; start at approximately 0.85 Dice, the convergence of the vanilla versions, and converge to about 0.91 and 0.92 Dice, respectively. Figure 2. A comparison of our best models’ Dice score (left) and BCE loss (right) from training. Note that the y-axis is scaled to the range of values. DenseNet had the highest and most variant BCE loss, yet its outlier values are relatively low compared to those in other binary classification tasks as BCE does not have an upper bound. Figure 3. Sample frame from the side-by-side video reconstruction of the input, ground truth, automated prediction with U-Net&#43;&#43;, and heat map (left to right). The heat map is the raw probability output per pixel whereas the predicted segmentation is the pixels with probabilities ≥ 0.5. The model was able to compute this output at 30 FPS. Table 1. Summary of the statistics gathered for each model. Non-parenthetical values are the average scores from all frames in the test set. The reported value in parentheses is the maximum value recorded from each baseline’s validation during training. The highest performances between models for each metric are denoted in bold. U-Net&#43;&#43; claimed the highest scores in each metric on the test set. U-Net had the same test Dice score as U-Net&#43;&#43; but lower scores in all other metrics. DenseNet had relatively poor performance for all metrics. Only the ROC curves from test set performances are included. Video 1. Example performance video of our best U-Net&#43;&#43; video on new data, not in train / val / test sets. The video shows a saline treatment and a stone that is being broken down with a laser. Detritus from the laser treatment is collecting to the left of the stone. This video is a typical example of what the model would see in a practical setting. Future To deploy our high-performing model for surgical use in operating rooms, we will extend our video processing script to receive “in-step” frame-by-frame video input from a video capture card connected via DVI/HDMI to the endoscopic hardware. Then, we will output the side-by-side frames, as in Figure 5, to an adjacent monitor to assist physicians in surgery. Developing such a system will allow us to investigate further goals, such as monocular depth prediction which might prove critical in automation.18
We will also investigate the application of temporal models for our system. Incorporating information from previous frames might allow for more consistent prediction between subsequent frames. In addition, such models account for memory of data from previous frames without the overhead of additional input dimensions suffered by our current fully convolutional models. For this task, we will incorporate self-attention modules into our U-Net and U-Net&#43;&#43; architectures, which has been shown to increase performance in video segmentation.19
In practice, the problem domain also requires the segmentation of kidney stones after they have been surgically broken down into smaller pieces. The current dataset has been developed to support the segmentation of only whole kidney stones. Further development will include expansion of another section of the dataset where, as a surgeon breaks stones apart, the debris fragments will still be labeled by our model. In Figure 5, our model already segments clumps of debris; however, our future goal is finer granularity via an instance segmentation method.20
Additionally, we plan to incorporate multi-class segmentation to also identify, for example, healthy vs. un- healthy tissue. Since the task performs well on stone segmentation, we hypothesize that we can utilize the same underlying architectures to adapt to multi-class segmentation and that the model will perform similarly well, with relatively few manually annotated examples.21
References [1] Minaee, S., Boykov, Y. Y., Porikli, F., Plaza, A. J., Kehtarnavaz, N., and Terzopoulos, D., “Image Seg- mentation Using Deep Learning: A Survey,” IEEE Transactions on Pattern Analysis and Machine Intelli- gence 8828(c), 1–20 (2021).
[2] Zaitoun, N. M. and Aqel, M. J., “Survey on Image Segmentation Techniques,” in [Procedia Computer Science], 65, 797–806, Elsevier (jan 2015).
[3] Badrinarayanan, V., Kendall, A., and Cipolla, R., “SegNet: A Deep Convolutional Encoder-Decoder Ar- chitecture for Image Segmentation,” IEEE Transactions on Pattern Analysis and Machine Intelligence 39, 2481–2495 (dec 2017).
[4] Ronneberger, O., Fischer, P., and Brox, T., “U-net: Convolutional networks for biomedical image segmen- tation,” in [Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)], 9351, 234–241, Springer International Publishing, Cham (2015).
[5] Chen, L. C., Papandreou, G., Schroff, F., and Adam, H., “Rethinking atrous convolution for semantic image segmentation,” (jun 2017).
[6] Simonyan, K. and Zisserman, A., “Very deep convolutional networks for large-scale image recognition,” in [3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings], International Conference on Learning Representations, ICLR (sep 2015).
[7] Zhou, Z., Siddiquee, M. M. R., Tajbakhsh, N., Liang, J., Rahman Siddiquee, M. M., Tajbakhsh, N., and Liang, J., “UNet&#43;&#43;: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation,” IEEE Transactions on Medical Imaging 39(6), 1856–1867 (2020).
[8] Safi, S., Thiessen, T., and Schmailzl, K. J., “Acceptance and Resistance of New Digital Technologies in Medicine: Qualitative Study,” JMIR Res Protoc 7, e11072 (Dec 2018).
[9] Nithya, A., Appathurai, A., Venkatadri, N., Ramji, D. R., and Anna Palagan, C., “Kidney disease detection and segmentation using artificial neural network and multi-kernel k-means clustering for ultrasound images,” Measurement: Journal of the International Measurement Confederation 149, 106952 (jan 2020).
[10] Viswanath, K. and Gunasundari, R., “Design and analysis performance of kidney stone detection from ultrasound image by level set segmentation and ANN classification,” in [2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)], IEEE (sep 2014).
[11] Jegou, S., Drozdzal, M., Vazquez, D., Romero, A., and Bengio, Y., “The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation,” IEEE CVPR Workshops , 1175–1183 (2017).
[12] Huang, G., Liu, Z., Van Der Maaten, L., and Weinberger, K. Q., “Densely connected convolutional net- works,” IEEE CVPR 2017-Janua, 2261–2269 (2017).
[13] Otsu, N., “A Threshold Selection Method from Gray-level Histograms,” IEEE Transactions on Systems, Man and Cybernetics 9(1), 62–66 (1979).
[14] He, K., Zhang, X., Ren, S., and Sun, J., “Deep residual learning for image recognition,” IEEE CVPR 2016- Decem, 770–778 (2016).
[15] Sørensen, T., “A method of establishing groups of equal amplitude in plant sociology based on similar- ity of species and its application to analyses of the vegetation on danish commons”,” Kongelige Danske Videnskabernes Selskab 5(4), 1–34 (1948).
[16] Iremashvili, V., Li, S., Penniston, K. L., Best, S. L., Hedican, S. P., and Nakada, S. Y., “Role of Residual Fragments on the Risk of Repeat Surgery after Flexible Ureteroscopy and Laser Lithotripsy: Single Center Study,” J Urol 201, 358–363 (02 2019).
[17] Ward, T. M., Mascagni, P., Ban, Y., Rosman, G., Padoy, N., Meireles, O., and Hashimoto, D. A., “Computer vision in surgery,” Surgery 169(5), 1253–1256 (2021).
[18] Fu, H., Gong, M., Wang, C., Batmanghelich, K., and Tao, D., “Deep ordinal regression network for monoc- ular depth estimation,” in [Proceedings of the IEEE conference on computer vision and pattern recognition], 2002–2011 (2018).
[19] Ji, G.-P., Chou, Y.-C., Fan, D.-P., Chen, G., Fu, H., Jha, D., and Shao, L., “Progressively normalized self-attention network for video polyp segmentation,” arXiv preprint arXiv:2105.08468 (2021).
[20] Zhou, Y., Onder, O. F., Dou, Q., Tsougenis, E., Chen, H., and Heng, P.-A., “Cia-net: Robust nuclei instance segmentation with contour-aware information aggregation,” in [International Conference on Information Processing in Medical Imaging], 682–693, Springer (2019).
[21] Kayalibay, B., Jensen, G., and van der Smagt, P., “Cnn-based segmentation of medical imaging data,” arXiv preprint arXiv:1701.03056 (2017).
]]></content:encoded>
    </item>
    <item>
      <title>dimensionality reduction on neural data</title>
      <link>/projects/neural-dim/</link>
      <pubDate>Mon, 28 Jun 2021 01:58:15 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/projects/neural-dim/</guid>
      <description>I fell in love with dimensionality reduction when I was learning statistical ML. Since I also study neuroscience, I wanted to practice the art at the intersection of my interests. I compared the 3D projections of a 53-dimensional neurophysiology dataset produced by PCA and a shallow autoencoder.</description>
      <category domain="/categories/course">Course</category>
      <category domain="/categories/solo">Solo</category>
      <content:encoded><![CDATA[ A shallow autoencoder&#39;s projection of 53-dimensional vectors to 3 dimensions. tl;dr I fell in love with dimensionality reduction when I was learning statistical ML. Since I also study neuroscience, I wanted to practice the art at the intersection of my interests. I compared the 3D projections of a 53-dimensional neurophysiology dataset produced by PCA and a shallow autoencoder.
Links repo
report
Motivation As I began learning about ML and statistical ML in particular, I became fascinated by dimensionality reduction (DR) methods. For those that don&amp;rsquo;t know, DRs project data from a high-dimensional space to a low-dimensional space. In essence, they are generalizations of the vector projection methods onto the x-, y-, and z-axes taught in a multivariable calculus course. DR is akin to conventional information compression, trading off size for information loss so choosing the best method and lower dimension is as much art as it is strategy.
Content I used this project to put fingers to keyboard and learn through implementation. I explored two avenues, applying
PCA An autoencoder to a waveform-to-cell type classification problem.
PCA is the OG DR method. It decomposes the covariance matrix of the dataset to discover components that explain the most variance of the dataset. Then, the dataset is projected onto these components, which often times could .
Autoencoders (AEs) are a deep neural network (DNN) that learns to encode examples in a dataset to a lower dimensional latent vector and then decode the latent vector back to the original example. Usually, AEs learn to project examples to a manifold, i.e., they are non-linear DR methods.
Essentially, this project compares linear vs. non-linear DR.
Method Dataset The dataset and article Sofroniew, Nicholas James et al. “Neural coding in barrel cortex during whisker-guided locomotion.” can be found on the author&amp;rsquo;s GitHub repo. Of the 16,000 recorded neurons, approx. 30 neurons were recorded for each of 13 subjects. Each recording was comprised of 53 voltage measurements. Overall, the dataset is composed of 302 waveforms. Unavoidably, the dataset is unbalanced; regular spikers comprise 247 of the examples while intermediate spikers only make up 4 examples.
Figure 1. Summary of the waveforms with mean waveform (left) and waveform distributions by cell type (right). Note that the mean waveform is essentially the tightly bounded waveform distribution for regular spikers, which dominate the dataset. Classification To compare and contrast the baseline, PCA, and autoencoding, I implemented a KNN classifier that uses Euclidean distance and majority vote for classification. To find the best number of neighbors given the dataset, I ran it through a standard hyperparameter search using cross-validation and a stratified split of the dataset to mitigate unbalanced classes. Once a good k-value was found, I evaluated the model on the test set, as well as a reclassification of the training set for debugging purposes.
Results The experiments for PCA and autoencoding had the same structure: 1. find the best reduced dimensionality, 2. reduce the dataset, and 3. test with KNN.
Figure 2. Scree plot (left) and cumulative explained variance of the first N components (right) from PCA applied to the waveforms. Table 1. Baseline results for a KNN fit on 53-dimensional waveform feature vectors. Table 2. PCA results for a KNN fit on 3- dimensional waveform components. Figure 3. 3D spatial distribution of the waveform principal components from PCA. Table 3. Autoencoding results for a KNN fit on 3-dimensional waveform components. Figure 4. 3D spatial distribution of the encodings from the bottleneck layer of the autoencoder. For both PCA and autoencoding, the accuracy is only slightly worse than that of the baseline. For PCA, the test accuracy is exactly the same for the 3 seeds while for the autoencoder it is only slightly worse. On the other hand, for the debug accuracy, PCA performs worse than the baseline while the autoencoder performs better. Given that trend, it might suggest that the autoencoder is somewhat overfitting the dataset, diminishing its generalizability. However, the test accuracy suggests that it is not significantly detrimental. All in all, dimensionality reduction still yields data suitable for high performance, even with information loss.
Future PCA is a fixed method but AEs are newer and more flexible. A whole study could be done just exploring AE architectures that yield the best projection for this classification task, not to mention other relevant tasks. Of course, other non-DNN non-linear DR methods could be applied to this dataset, which would be particularly interesting for the classification of waveform to subject. Perhaps one of those methods or an AE would be able to adequately separate these classes, which were not easily separable by PCA when I tried.
Figure 5. 3D spatial distribution of the waveform principal components from PCA for each subject. PCA could not separate these overlapping classes very well,. References Cunningham, J., Yu, B. Dimensionality reduction for large-scale neural recordings. Nat Neurosci 17, 1500–1509 (2014). https://doi.org/10.1038/nn.3776
Paninski L, Cunningham JP. Neural data science: accelerating the experiment-analysis- theory cycle in large-scale neuroscience. Curr Opin Neurobiol. 2018 Jun;50:232-241. doi: 10.1016/j.conb.2018.04.007. PMID: 29738986.
Wu, Tong et al. “Deep Compressive Autoencoder for Action Potential Compression in Large-Scale Neural Recording.” Journal of Neural Engineering 15.6 (2018): n. pag. Journal of Neural Engineering. Web.
Ladjal, Saïd, Alasdair Newson, and Chi Hieu Pham. “A PCA-like Autoencoder.” arXiv 2 Apr. 2019: n. pag. Print.
Scree and cumulative explained variance plots
Matplotlib 3D scatter plot
Keras autoencoder guide
Hyperparameter grid search for Keras:
https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/ https://stackoverflow.com/questions/49823192/autoencoder-gridsearch-hyperparameter-tuning-keras https://towardsdatascience.com/autoencoders-for-the-compression-of-stock-market-data-28e8c1a2da3e ]]></content:encoded>
    </item>
  </channel>
</rss>
