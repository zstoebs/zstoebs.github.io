<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <docs>https://blogs.law.harvard.edu/tech/rss</docs>
    <title>python on Zach Stoebner | ml • neuro • kū</title>
    <link>/tags/python/</link>
    <description>Recent content in python on Zach Stoebner | ml • neuro • kū</description>
    <image>
      <title>python on Zach Stoebner | ml • neuro • kū</title>
      <link>/tags/python/</link>
      <url>https://source.unsplash.com/collection/983219/2000x1322</url>
    </image>
    <ttl>1440</ttl>
    <generator>After Dark 9.2.3 (Hugo 0.81.0)</generator>
    <language>en-US</language>
    <copyright>Copyright &amp;copy; Zachary Stoebner. Licensed under CC-BY-ND-4.0.</copyright>
    <lastBuildDate>Mon, 03 Jan 2022 17:36:37 UT</lastBuildDate>
    <atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>segmentation of kidney stones in endoscopic video feeds</title>
      <link>/projects/stone-anno/</link>
      <pubDate>Mon, 08 Nov 2021 02:39:01 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/projects/stone-anno/</guid>
      <description>StoneAnno is my first published first-authorship paper, presenting at SPIE 2022. With the long-term goal of fully-automated robotic endoscopic surgery, we built a dataset of endoscopic kidney stone removal videos and investigated U-Net, U-Net&#43;&#43;, and DenseNet for the segmentation task. We found a U-Net&#43;&#43; model that consistently achieves &amp;gt;0.9 Dice score, with low loss, and produces realistic, convincing segmentations. Moving forward, I am implementing our model on hardware for deployment in ORs, as a part of my master&amp;rsquo;s thesis, and I helped Dr. Kavoussi submit an R21 grant in October 2021.</description>
      <category domain="/categories/research">Research</category>
      <content:encoded><![CDATA[tl;dr StoneAnno is my first published first-authorship paper, presenting at SPIE 2022. My advisor, Prof. Ipek Oguz, connected me and my friend, David Lu, with Dr. Nick Kavoussi at VUMC who wanted to bring surgical endoscopy out of the dark ages. With the long-term goal of fully-automated robotic endoscopic surgery, we built a dataset of endoscopic kidney stone removal videos and investigated U-Net, U-Net&#43;&#43;, and DenseNet for the segmentation task. We found a U-Net&#43;&#43; model that consistently achieves &amp;gt;0.9 Dice score, with low loss, and produces realistic, convincing segmentations. Moving forward, I am implementing our model on hardware for deployment in ORs, as a part of my master&amp;rsquo;s thesis, and I helped Dr. Kavoussi submit an R21 grant in October 2021. In the early stages of the project, we were also accepted for a poster presentation at the 2021 Engineering &amp;amp; Urology Society annual meeting.
Links The paper was accepted for SPIE 2022 Medical Imaging: Image Processing. Once the paper is digitally published on the SPIE archive, I will link it here. At that time, I expect to release the code as well.
comet.ml project page
Abstract Image segmentation has been increasingly applied in medical settings as the advent of AI has skyrocketed the application of deep learning. Urology, specifically, is one field of medicine that is primed for the adoption of a real-time image segmentation system with the aim of automating endoscopic stone treatment. In this project, we explored supervised deep learning models to annotate kidney stones in surgical endoscopic video feeds. In this paper, we describe how we built the dataset from the raw videos and how we developed a pipeline to automate as much of the process as possible. To maintain the project in the long term, we also began to engineer a utilities library to expedite data management at each endpoint of the model’s use. Most importantly, we adapted and analyzed three baseline deep learning models – U-Net, U-Net&#43;&#43;, and DenseNet – to predict annotations on the frames of the endoscopic videos with the highest accuracy above 90%. To show clinical promise, we also confirmed that our best trained model can accurately annotate new videos at 30 frames per second. Our results demonstrate that the proposed method justifies continued development and study of image segmentation to annotate ureteroscopic video feeds.
Results  Figure 1. A comparison of our best models’ Dice score (left) and BCE loss (right) from training. The scores were computed at each step where total steps = ⌈dataset length⌉ ∗ epochs. These curves display 20 epochs of training. Note that the batch size y-axis is scaled to the range of values. DenseNet had the highest and most variant BCE loss, yet its outlier values are relatively low compared to those in other binary classification tasks as BCE does not have an upper bound.    Figure 2. Sample frame from the side-by-side video reconstruction of the input, ground truth, automated prediction with U-Net&#43;&#43;, and heat map (left to right). The heat map is the raw probability output per pixel whereas the predicted segmentation is the pixels with probabilities ≥ 0.5. The model was able to compute this output at 30 FPS.     Table 1. Summary of the statistics gathered for each model. The reported value is the maximum value recorded from each baseline’s validation. The highest performances for each metric are denoted in bold. U-Net&#43;&#43; and U-Net claimed the highest scores, each in different metrics, except that they had the same average AUC for their ROC curves. However, the ROC curve is tighter for U-Net&#43;&#43;. DenseNet had relatively poor performance.    Video 1. Example performance video of our best U-Net&#43;&#43; video on new data, not in train / val / test sets. The video shows a saline treatment and a stone that is being broken down with a laser. Detritus from the laser treatment is collecting to the left of the stone. This video is a typical example of what the model would see in a practical setting.   Future This fall, I helped write an NIH R21 grant with Dr. Kavoussi and Dr. Oguz. Our two aims: 1. to develop a deep learning-based, automatic, real- time segmentation and tracking system during kidney stone surgery, and 2. to generate a real-time 3D navigational map of stone locations. Fingers crossed!!
Currently, I am working on a method to integrate our high-performing model with a contemporary endoscope. Next, I will design a visual GUI to extend the current view from the endoscope. We have shown that the model can compute results a little faster than 30 FPS so I expect that the system will be efficacious in practice. I&amp;rsquo;m planning on composing my work on this segmentation system into my master&amp;rsquo;s thesis.
References [1] Safi, S., Thiessen, T., and Schmailzl, K. J., “Acceptance and Resistance of New Digital Technologies in Medicine: Qualitative Study,” JMIR Res Protoc 7, e11072 (Dec 2018).
[2] Minaee, S., Boykov, Y. Y., Porikli, F., Plaza, A. J., Kehtarnavaz, N., and Terzopoulos, D., “Image Seg- mentation Using Deep Learning: A Survey,” IEEE Transactions on Pattern Analysis and Machine Intelli- gence 8828(c), 1–20 (2021).
[3] Nithya, A., Appathurai, A., Venkatadri, N., Ramji, D. R., and Anna Palagan, C., “Kidney disease detection and segmentation using artificial neural network and multi-kernel k-means clustering for ultrasound images,” Measurement: Journal of the International Measurement Confederation 149, 106952 (jan 2020).
[4] Viswanath, K. and Gunasundari, R., “Design and analysis performance of kidney stone detection from ultrasound image by level set segmentation and ANN classification,” in [2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)], IEEE (sep 2014).
[5] Jegou, S., Drozdzal, M., Vazquez, D., Romero, A., and Bengio, Y., “The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation,” IEEE CVPR Workshops , 1175–1183 (2017).
[6] Huang, G., Liu, Z., Van Der Maaten, L., and Weinberger, K. Q., “Densely connected convolutional networks,” IEEE CVPR 2017-Janua, 2261–2269 (2017).
[7] Otsu, N., “A Threshold Selection Method from Gray-level Histograms,” IEEE Transactions on Systems, Man and Cybernetics 9(1), 62–66 (1979).
[8] He, K., Zhang, X., Ren, S., and Sun, J., “Deep residual learning for image recognition,” IEEE CVPR 2016- Decem, 770–778 (2016).
[9] Sørensen, T., “A method of establishing groups of equal amplitude in plant sociology based on similarity of species and its application to analyses of the vegetation on danish commons”,” Kongelige Danske Vidensk- abernes Selskab 5(4), 1–34 (1948).
]]></content:encoded>
    </item>
    <item>
      <title>dimensionality reduction on neural data</title>
      <link>/projects/neural-dim/</link>
      <pubDate>Mon, 28 Jun 2021 01:58:15 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/projects/neural-dim/</guid>
      <description>I fell in love with dimensionality reduction when I was learning statistical ML. Since I also study neuroscience, I wanted to practice the art at the intersection of my interests. I compared the 3D projections of a 53-dimensional neurophysiology dataset produced by PCA and a shallow autoencoder.</description>
      <category domain="/categories/course">Course</category>
      <category domain="/categories/solo">Solo</category>
      <content:encoded><![CDATA[ A shallow autoencoder&#39;s projection of 53-dimensional vectors to 3 dimensions.  tl;dr I fell in love with dimensionality reduction when I was learning statistical ML. Since I also study neuroscience, I wanted to practice the art at the intersection of my interests. I compared the 3D projections of a 53-dimensional neurophysiology dataset produced by PCA and a shallow autoencoder.
Links repo
report
Motivation As I began learning about ML and statistical ML in particular, I became fascinated by dimensionality reduction  (DR) methods. For those that don&amp;rsquo;t know, DRs project data from a high-dimensional space to a low-dimensional space. In essence, they are generalizations of the vector projection methods onto the x-, y-, and z-axes taught in a multivariable calculus course. DR is akin to conventional information compression, trading off size for information loss so choosing the best method and lower dimension is as much art as it is strategy.
Content I used this project to put fingers to keyboard and learn through implementation. I explored two avenues, applying
 PCA An autoencoder  to a waveform-to-cell type classification problem.
PCA is the OG DR method. It decomposes the covariance matrix of the dataset to discover components that explain the most variance of the dataset. Then, the dataset is projected onto these components, which often times could .
Autoencoders (AEs) are a deep neural network (DNN) that learns to encode examples in a dataset to a lower dimensional latent vector and then decode the latent vector back to the original example. Usually, AEs learn to project examples to a manifold, i.e., they are non-linear DR methods.
Essentially, this project compares linear vs. non-linear DR.
Method Dataset The dataset and article Sofroniew, Nicholas James et al. “Neural coding in barrel cortex during whisker-guided locomotion.” can be found on the author&amp;rsquo;s GitHub repo. Of the 16,000 recorded neurons, approx. 30 neurons were recorded for each of 13 subjects. Each recording was comprised of 53 voltage measurements. Overall, the dataset is composed of 302 waveforms. Unavoidably, the dataset is unbalanced; regular spikers comprise 247 of the examples while intermediate spikers only make up 4 examples.
 Figure 1. Summary of the waveforms with mean waveform (left) and waveform distributions by cell type (right). Note that the mean waveform is essentially the tightly bounded waveform distribution for regular spikers, which dominate the dataset.  Classification To compare and contrast the baseline, PCA, and autoencoding, I implemented a KNN classifier that uses Euclidean distance and majority vote for classification. To find the best number of neighbors given the dataset, I ran it through a standard hyperparameter search using cross-validation and a stratified split of the dataset to mitigate unbalanced classes. Once a good k-value was found, I evaluated the model on the test set, as well as a reclassification of the training set for debugging purposes.
Results The experiments for PCA and autoencoding had the same structure: 1. find the best reduced dimensionality, 2. reduce the dataset, and 3. test with KNN.
 Figure 2. Scree plot (left) and cumulative explained variance of the first N components (right) from PCA applied to the waveforms.   Table 1. Baseline results for a KNN fit on 53-dimensional waveform feature vectors.   Table 2. PCA results for a KNN fit on 3- dimensional waveform components.   Figure 3. 3D spatial distribution of the waveform principal components from PCA.   Table 3. Autoencoding results for a KNN fit on 3-dimensional waveform components.   Figure 4. 3D spatial distribution of the encodings from the bottleneck layer of the autoencoder.  For both PCA and autoencoding, the accuracy is only slightly worse than that of the baseline. For PCA, the test accuracy is exactly the same for the 3 seeds while for the autoencoder it is only slightly worse. On the other hand, for the debug accuracy, PCA performs worse than the baseline while the autoencoder performs better. Given that trend, it might suggest that the autoencoder is somewhat overfitting the dataset, diminishing its generalizability. However, the test accuracy suggests that it is not significantly detrimental. All in all, dimensionality reduction still yields data suitable for high performance, even with information loss.
Future PCA is a fixed method but AEs are newer and more flexible. A whole study could be done just exploring AE architectures that yield the best projection for this classification task, not to mention other relevant tasks. Of course, other non-DNN non-linear DR methods could be applied to this dataset, which would be particularly interesting for the classification of waveform to subject. Perhaps one of those methods or an AE would be able to adequately separate these classes, which were not easily separable by PCA when I tried.
 Figure 5. 3D spatial distribution of the waveform principal components from PCA for each subject. PCA could not separate these overlapping classes very well,.  References Cunningham, J., Yu, B. Dimensionality reduction for large-scale neural recordings. Nat Neurosci 17, 1500–1509 (2014). https://doi.org/10.1038/nn.3776
Paninski L, Cunningham JP. Neural data science: accelerating the experiment-analysis- theory cycle in large-scale neuroscience. Curr Opin Neurobiol. 2018 Jun;50:232-241. doi: 10.1016/j.conb.2018.04.007. PMID: 29738986.
Wu, Tong et al. “Deep Compressive Autoencoder for Action Potential Compression in Large-Scale Neural Recording.” Journal of Neural Engineering 15.6 (2018): n. pag. Journal of Neural Engineering. Web.
Ladjal, Saïd, Alasdair Newson, and Chi Hieu Pham. “A PCA-like Autoencoder.” arXiv 2 Apr. 2019: n. pag. Print.
Scree and cumulative explained variance plots
Matplotlib 3D scatter plot
Keras autoencoder guide
Hyperparameter grid search for Keras:
 https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/ https://stackoverflow.com/questions/49823192/autoencoder-gridsearch-hyperparameter-tuning-keras https://towardsdatascience.com/autoencoders-for-the-compression-of-stock-market-data-28e8c1a2da3e  ]]></content:encoded>
    </item>
  </channel>
</rss>
