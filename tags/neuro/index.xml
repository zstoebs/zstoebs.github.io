<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <docs>https://blogs.law.harvard.edu/tech/rss</docs>
    <title>neuro on Zach Stoebner | ml • neuro • kū</title>
    <link>/tags/neuro/</link>
    <description>Recent content in neuro on Zach Stoebner | ml • neuro • kū</description>
    <image>
      <title>neuro on Zach Stoebner | ml • neuro • kū</title>
      <link>/tags/neuro/</link>
      <url>https://source.unsplash.com/collection/983219/2000x1322</url>
    </image>
    <ttl>1440</ttl>
    <generator>After Dark 9.2.3 (Hugo 0.81.0)</generator>
    <language>en-US</language>
    <copyright>Copyright &amp;copy; Zachary Stoebner. Licensed under CC-BY-ND-4.0.</copyright>
    <lastBuildDate>Sat, 04 Dec 2021 21:05:58 UT</lastBuildDate>
    <atom:link href="/tags/neuro/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>on fiber tracking</title>
      <link>/notes/fiber-tracking/</link>
      <pubDate>Tue, 16 Nov 2021 19:50:49 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/notes/fiber-tracking/</guid>
      <description>After brief description of diffusion tensor images and what information they provide, I discuss an intuitive seed-based line propagation algorithm for computing a tractography map of a neuroimage. The open-source softwares required are 3D Slicer, ITK for C&#43;&#43;, and ITK-SNAP.</description>
      <category domain="/categories/algo">Algo</category>
      <content:encoded><![CDATA[tl;dr After brief description of diffusion tensor images and what information they provide, I discuss an intuitive seed-based line propagation algorithm for computing a tractography map of a neuroimage. A stack of open-source softwares that can be used to implement diffusion tensor tractography are 3D Slicer, ITK for C&#43;&#43;, and ITK-SNAP.
The diffusion tensor image used to generate all figures is publically available as sample data, DTIBrain, via 3D Slicer.
Diffusion Tensor Imaging In a diffusion tensor image (DTI), each voxel is represented by a symmetric tensor with 6 distinct values for the speed of water diffusion, corresponding to the directions from the center of the cubic voxel to each of its faces. Without obstruction, water diffusion is uniform on average in every direction; however, in spaces that alter diffusion, the values in each of these directions are anisotropic. Anisotropic diffusion gives rise to a principal axis of diffusion where some forward and backwards direction have greater values than the rest. Hence, the tensor at the voxel can be visualized as an ellipsoid – the elastic deformation of the cube along the principal axis.
 Sagittal slice of a DTI. 3D Slicer visualizes DTI well with a color orientation scheme, where red means that the principal eigenvector is along the left-right axis, blue means its along the inferior-superior axis, and green means its along the anterior-posterior axis. Intermediate colors means that its along a linear combination of these basis vectors.  Principal Eigenvector The major eigenvector from each diffusion tensor gives the forward direction of the principal axis; the negation of the major eigenvector is the backwards direction. Precomputing this vector image, with one vector at each voxel, yields a map that can be used to route the line propagation algorithm through the brain&amp;rsquo;s tracts. ITK defines a DiffusionTensor3D type that can set as the pixel type for an image; the type also defines a function for computing its eigendecomposition, which can be called when the pixel is accessed by an iterator.
 Sagittal slice of the principal eigenvector image of the DTI. Although it&#39;s noisy, you can see that there is still structure to it that makes sense, i.e., in the corpus callosum and the brain stem.  Fractional Anisotropy Fractional anisotropy (FA) is a scalar value computed from the eigenvalues of the diffusion tensor to quantify the amount of anisotropic diffusion at a voxel in the DTI [3]. A high value insinuates that water diffuses along a single axis, which would correspond to water flowing through a tract. FA for a 3x3 diffusion tensor is computed as follows:
 The formula to compute the scalar FA value, which is solely based on the eigenvalues, where the capped lambda is the mean of the eigenvalues.  When performing tractography, an FA value that is too low implies that water diffusion is largely isotropic, e.g., in grey matter, where there are no tracts. Hence, a minimum FA can be set and used as a stopping condition at a given voxel. ITK&amp;rsquo;s DiffusionTensor3D type defines a function to compute the FA value of the tensor and can be accessed in the same way as the eigendecomposition function.
 Sagittal slice of the FA image of the DTI. The FA image looks strikingly similar to a structural MRI.  Tractography With the directional values, a line can be propagated from a seed voxel along the 3D vector field to reconstruct a 3D tract down the two directions of the principal axis [1]. By propagating a line from a seed, or from many seeds, a rudimentary tractography map of a DTI can be computed. Although line propagation is intuitive and relatively lightweight, it is worth noting that other fiber tracking techniques exist that are both more robust and more intensive [2].
The stopping conditions:
 Current iteration is greater than the max number of iterations chosen by the user. The candidate voxel is outside of the image. The FA at the candidate voxel is below the minimum FA acceptable chosen by the user. The candidate voxel has already been visited.  If no stopping condition was met, then the current voxel was visited, meaning:
 The candidate voxel in the tractography image was set to a non-negative integer. The eigenvector at the candidate voxel was extracted, multiplied by some step size ∆ chosen by the user, added and subtracted from the candidate voxel’s index, and then pushed to the back of the list. Finally, the candidate voxel was popped from the front of the list and the iteration was incremented.  For this task, line propagation can be implemented both iteratively or recursively because it is isomorphic to search algorithms, i.e., breadth-first and depth-first search. Switching between the two is pretty straightforward as the function definitions should not be very different. That said, the recursive algorithm is likely less bloated and more effective computationally, but might be much slower if you&amp;rsquo;re using ITK in Python rather than C&#43;&#43;.
 Views of a tractography image generated by a single seed (top) and multiple seeds from a segmentation image (bottom) for ∆ = 0.9, minimum FA at 0.1, and the maximum number of iterations at 10000. The orientation of the views is given on the top. As expected, multi-seed input generated a much more extensive tractography map.  References [1] Mori S, van Zijl PC. Fiber tracking: principles and strategies - a technical review. NMR Biomed. 2002 Nov-Dec;15(7-8):468-80. https://doi.org/10.1002/nbm.781. PMID: 12489096.
[2] Kleiser R, Staempfli P, Valavanis A, Boesiger P, Kollias S. Impact of fMRI- guided advanced DTI fiber tracking techniques on their clinical applica- tions in patients with brain tumors. Neuroradiology. 2010 Jan;52(1):37-46. https://doi.org/10.1007/s00234-009-0539-2. Epub 2009 May 29. PMID: 19479248.
[3] Basser PJ, Pierpaoli C. Microstructural and physiological features of tissues eluci- dated by quantitative-diffusion-tensor MRI. J Magn Reson B. 1996 Jun;111(3):209- 19. https://doi.org/10.1006/jmrb.1996.0086. PMID: 8661285.
]]></content:encoded>
    </item>
    <item>
      <title>cortical surface analysis in Huntington&#39;s disease using linear-mixed models</title>
      <link>/projects/cortical-surface-analysis/</link>
      <pubDate>Tue, 14 Sep 2021 15:38:19 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/projects/cortical-surface-analysis/</guid>
      <description>Although it will be published after StoneAnno, this shape analysis is my first completed research project and technically my first first-authorship, going for submission at Brain. I wrote code in R and MATLAB to fit LMMs to the cortical data from T1w MRI of HD patients and then performed statistical analyses on the results using SurfStat and random field theory. We found that, with a novel method for measuring gyrification, LGI uniquely detects changes in the insula.</description>
      <category domain="/categories/research">Research</category>
      <content:encoded><![CDATA[tl;dr Although it will be published after StoneAnno, this shape analysis is my first completed research project and technically my first first-authorship, going for submission at Brain. I wrote code in R and MATLAB to fit LMMs to the cortical data from T1w MRI of HD patients and then performed statistical analyses on the results using SurfStat and random field theory. We found that, with a novel method for measuring gyrification, LGI uniquely detects changes in the insula. Of note, I learned that complicated statistical anlayses are uniquely challenging, that I love LMMs and RFT, and that they are too esoteric in the current day &amp;ndash; let&amp;rsquo;s make them more accessible!
Links We are in the process of submitting our manuscript at Brain. As soon as it&amp;rsquo;s published, I will link it here. At that time, I expect to release the code as well.
Background LMMs
random field theory
LGI acquisition method
Abstract The striatum has traditionally been the focus of Huntington’s disease research due to the resulting primary insult and its central role in motor symptoms. Beyond the striatum, evidence of cortical alterations caused by Huntington’s disease has surfaced; however, findings are not coherent between studies. A number of studies have used cortical thickness as the cortical metric of interest due to its establishment in the role of Huntington’s disease. In this study, we propose a more comprehensive approach to cortical morphology using cortical thickness (CT), sulcal depth (SD), and local gyrification index (LGI). Our results show consistency with prior findings in cortical thickness, including its limitations. Comparing between cortical thickness and local gyrification index underscores the complementary nature of these two measures; cortical thickness detects changes in the sensorimotor and posterior areas while local gyrification index identifies insular differences. Since the local gyrification index and cortical thickness measures detect changes in different regions, the two used in tandem could provide a clinically relevant measure of disease progression. Our findings suggest that differences in insular regions correspond to earlier neurodegeneration and may provide a complementary cortical measure for detection of subtle cortical changes due to Huntington’s disease.
Results These results are only the top-most. for all of the tables, charts, etc., please check out the paper once it is published.
CT  Fig 1. Omnibus test results for CT showing the regions of significant contrast across all patients compared to controls. P-values were adjusted for FWER using random field theory (\alpha=0.01).   SD  Fig 2. Omnibus test results for SD showing the regions of significant contrast across all patients compared to controls. P-values were adjusted for FWER using random field theory (\alpha=0.01).   LGI  Fig 3. Omnibus test results for LGI showing the regions of significant contrast across all patients compared to controls. P-values were adjusted for FWER using random field theory (\alpha=0.01).   Summary   Table 1. Summary of Regions with Significant Changes Per Feature. The percentage of the structure with significant changes are reported, in terms of the number of vertices. Regions are color-coded according to cooccurrence in the three features. Red = regional changes were detected by all three features. Yellow = regional changes were detected by two of the features. Blue = regional changes were detected by one of the features.   Takeaways A main takeaway was learning the scientific process in action and, most importantly, learning to work with more experienced researchers. I wrote the code and performed all of the analysis that produced our results. However, I did not develop the awesome acquisition method that generated our LGI data nor the statistical theory behind the analysis. Throughout the project, I have relied heavily on the expertise of my co-authors &amp;ndash; all of whom have PhDs whereas I was an undergrad until recently. This first journey in research has been inspiring and indelible. I am beyond grateful for it!
References [1] F. O. Walker, “Huntington’s disease,” Lancet, vol. 369, no. 9557, pp. 218–228, 2007, doi: 10.1016/S0140-6736(07)60111-1.
[2] J. D. Long et al., “Genetic Modification of Huntington Disease Acts Early in the Prediagnosis Phase,” Am. J. Hum. Genet., vol. 103, no. 3, pp. 349–357, 2018, doi: 10.1016/j.ajhg.2018.07.017.
[3] J. S. Paulsen et al., “Prediction of manifest Huntington disease with clinical and imaging measures : A 12-year prospective observational study,” vol. 13, no. 12, pp. 1193–1201, 2015, doi: 10.1016/S1474-4422(14)70238-8.Prediction.
[4] M. E. Ehrlich, “Huntington’s Disease and the Striatal Medium Spiny Neuron: Cell-Autonomous and Non-Cell-Autonomous Mechanisms of Disease,” Neurotherapeutics, vol. 9, no. 2, pp. 270–284, 2012, doi: 10.1007/s13311-012-0112-2.
[5] K. Hett, H. Johnson, P. Coupe, J. S. Paulsen, J. D. Long, and I. Oguz, “Tensor-Based Grading: A Novel Patch-Based Grading Approach for the Analysis of Deformation Fields in Huntington’s Disease,” Proc. - Int. Symp. Biomed. Imaging, vol. 2020-April, pp. 1091–1095, 2020, doi: 10.1109/ISBI45749.2020.9098692.
[6] H. Li, H. Zhang, H. Johnson, J. Long, J. Paulsen, and I. Oguz, “Longitudinal subcortical segmentation with deep learning,” in SPIE Medical Imaging 2021: Image Processing, 2021, p. 115960D, doi: https://doi.org/10.1117/12.2582340.
[7] H. Li et al., “Generalizing MRI subcortical segmentation to Neurodegeneration,” in MLCN Workshop, MICCAI, 2020, pp. 139–147, doi: https://doi.org/10.1007/978-3-030-66843-3_14.
[8] H. Li, H. Zhang, H. Johnson, J. Long, J. Paulsen, and I. Oguz, “MRI Subcortical Segmentation In Neurodegeneration with Cascaded 3D CNNs,” in SPIE Medical Imaging 2021: Image Processing, 2021, p. 115960W, doi: https://doi.org/10.1117/12.2582005.
[9] J. S. Paulsen et al., “Striatal and white matter predictors of estimated diagnosis for Huntington disease,” Brain Res. Bull., vol. 82, no. 3–4, pp. 201–207, 2010, doi: 10.1016/j.brainresbull.2010.04.003.
[10] J. C. Hedreen, C. E. Peyser, S. E. Folstein, and C. A. Ross, “Neuronal loss in layers V and VI of cerebral cortex in Huntington’s disease,” Neurosci. Lett., vol. 133, no. 2, pp. 257–261, 1991, doi: 10.1016/0304-3940(91)90583-F.
[11] H. D. Rosas et al., “Regional and progressive thinning of the cortical ribbon in Huntington’s disease,” Neurology, vol. 58, no. 5, pp. 695–701, 2002, doi: 10.1212/WNL.58.5.695.
[12] P. C. Nopoulos et al., “Cerebral cortex structure in prodromal Huntington disease,” Neurobiol. Dis., vol. 40, no. 3, pp. 544–554, 2010, doi: 10.1016/j.nbd.2010.07.014.
[13] S. J. Tabrizi et al., “Biological and clinical manifestations of Huntington’s disease in the longitudinal TRACK-HD study: cross-sectional analysis of baseline data Sarah,” vol. 8, no. 9, pp. 791–801, 2013, doi: 10.1016/S1474-4422(09)70170-X.Biological.
[14] B. Fischl and A. M. Dale, “Measuring the thickness of the human cerebral cortex from magnetic resonance images,” Proc. Natl. Acad. Sci. U. S. A., vol. 97, no. 20, pp. 11050–11055, 2000, doi: 10.1073/pnas.200033797.
[15] I. Lyu, H. Kang, N. D. Woodward, and B. A. Landman, “Sulcal depth-based cortical shape analysis in normal healthy control and schizophrenia groups,” vol. 1057402, no. March 2018, p. 1, 2018, doi: 10.1117/12.2293275.
[16] I. Lyu, S. H. Kim, J. B. Girault, J. H. Gilmore, and M. A. Styner, “A cortical shape-adaptive approach to local gyrification index,” Med. Image Anal., vol. 48, pp. 244–258, 2018, doi: 10.1016/j.media.2018.06.009.
[17] D. Wu, A. V. Faria, L. Younes, C. A. Ross, S. Mori, and M. I. Miller, “Whole-brain segmentation and change-point analysis of anatomical brain mri—application in premanifest huntington’s disease,” J. Vis. Exp., vol. 2018, no. 136, pp. 1–9, 2018, doi: 10.3791/57256.
[18] X. Tan, C. A. Ross, M. I. Miller, and X. Tang, “CHANGEPOINT ANALYSIS OF PUTAMEN AND THALAMUS SUBREGIONS IN PREMANIFEST HUNTINGTON’S DISEASE,” in 2018 IEEE 15th International Symposium on Biomedical Imaging, 2018, no. ISBI, pp. 531–535, doi: 10.1109/ISBI.2018.8363632.
[19] X. Tang et al., “Regional subcortical shape analysis in premanifest Huntington’s disease,” Hum. Brain Mapp., vol. 40, no. 5, pp. 1419–1433, 2019, doi: 10.1002/hbm.24456.
[20] Y. Hong et al., “Genetic load determines atrophy in hand cortico-striatal pathways in presymptomatic Huntington’s disease,” Hum. Brain Mapp., vol. 39, no. 10, pp. 3871–3883, 2018, doi: 10.1002/hbm.24217.
[21] J. S. Paulsen et al., “Detection of Huntington’s disease decades before diagnosis: The Predict-HD study,” J. Neurol. Neurosurg. Psychiatry, vol. 79, no. 8, pp. 874–880, 2008, doi: 10.1136/jnnp.2007.128728.
[22] Y. Zhang, J. D. Long, J. A. Mills, J. H. Warner, W. Lu, and J. S. Paulsen, “Indexing disease progression at study entry with individuals at-risk for Huntington disease,” Am. J. Med. Genet. Part B Neuropsychiatr. Genet., vol. 156, no. 7, pp. 751–763, 2011, doi: 10.1002/ajmg.b.31232.
[23] B. Fischl, “FreeSurfer,” Neuroimage, vol. 62, no. 2, pp. 774–781, 2012, doi: 10.1016/j.neuroimage.2012.01.021.FreeSurfer.
[24] I. Lyu, H. Kang, N. D. Woodward, M. A. Styner, and B. A. Landman, “Hierarchical spherical deformation for cortical surface registration,” Med. Image Anal., vol. 57, pp. 72–88, 2019, doi: 10.1016/j.media.2019.06.013.
[25] P. Parvathaneni et al., “Cortical Surface Parcellation Using Spherical Convolutional Neural Networks,” Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), vol. 11766 LNCS, pp. 501–509, 2019, doi: 10.1007/978-3-030-32248-9_56.
[26] A. Klein et al., “Open labels: online feedback for a public resource of manually labeled brain images,” 16th Annu. Meet. Organ. Hum. Brain Mapping., p. 84358, 2010.
[27] T. W. J. Moorhead et al., “Automated computation of the Gyrification Index in prefrontal lobes: Methods and comparison with manual implementation,” Neuroimage, vol. 31, no. 4, pp. 1560–1566, 2006, doi: 10.1016/j.neuroimage.2006.02.025.
[28] M. Roberts, J. Hanaway, and D. K. Morest, Atlas of the Human Brain in Section, 2nd ed. Lea &amp;amp; Febiger, 1970.
[29] I. Lyu, S. H. Kim, N. D. Woodward, M. A. Styner, and B. A. Landman, “TRACE: A Topological Graph Representation for Automatic Sulcal Curve Extraction,” IEEE Trans. Med. Imaging, vol. 37, no. 7, pp. 1653–1663, 2018, doi: 10.1109/TMI.2017.2787589.
[30] A. Alin, “Multicollinearity,” Wiley Interdiscip. Rev. Comput. Stat., vol. 2, no. 3, pp. 370–374, 2010, doi: 10.1002/wics.84.
[31] G. Verbeke and G. Molenberghs, Linear Mixed Models for Longitudinal Data, Print. New York: Spinger, 2000.
[32] K. J. Worsley, M. Andermann, T. Koulis, D. MacDonald, and A. C. Evans, “Detecting changes in nonisotropic images,” Hum. Brain Mapp., vol. 8, no. 2–3, pp. 98–101, 1999, doi: 10.1002/(SICI)1097-0193(1999)8:2/3&amp;lt;98::AID-HBM5&amp;gt;3.0.CO;2-F.
[33] J. E. Taylor and K. J. Worsley, “Detecting sparse signals in random fields, with an application to brain mapping,” J. Am. Stat. Assoc., vol. 102, no. 479, pp. 913–928, 2007, doi: 10.1198/016214507000000815.
[34] D. Bates, M. Mächler, B. M. Bolker, and S. C. Walker, “Fitting linear mixed-effects models using lme4,” J. Stat. Softw., vol. 67, no. 1, 2015, doi: 10.18637/jss.v067.i01.
[35] K. Worsley et al., “SurfStat: A Matlab toolbox for the statistical analysis of univariate and multivariate surface and volumetric data using linear mixed effects models and random field theory,” Neuroimage, vol. 47, p. S102, 2009, doi: 10.1016/s1053-8119(09)70882-1.
[36] X. Han et al., “Reliability of MRI-derived measurements of human cerebral cortical thickness: The effects of field strength, scanner upgrade and manufacturer,” Neuroimage, vol. 32, no. 1, pp. 180–194, 2006, doi: 10.1016/j.neuroimage.2006.02.051.
]]></content:encoded>
    </item>
    <item>
      <title>dimensionality reduction on neural data</title>
      <link>/projects/neural-dim/</link>
      <pubDate>Mon, 28 Jun 2021 01:58:15 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>/projects/neural-dim/</guid>
      <description>I fell in love with dimensionality reduction when I was learning statistical ML. Since I also study neuroscience, I wanted to practice the art at the intersection of my interests. I compared the 3D projections of a 53-dimensional neurophysiology dataset produced by PCA and a shallow autoencoder.</description>
      <category domain="/categories/course">Course</category>
      <content:encoded><![CDATA[ A shallow autoencoder&#39;s projection of 53-dimensional vectors to 3 dimensions.  tl;dr I fell in love with dimensionality reduction when I was learning statistical ML. Since I also study neuroscience, I wanted to practice the art at the intersection of my interests. I compared the 3D projections of a 53-dimensional neurophysiology dataset produced by PCA and a shallow autoencoder.
Links GitHub
Paper
Motivation As I began learning about ML and statistical ML in particular, I became fascinated by dimensionality reduction  (DR) methods. For those that don&amp;rsquo;t know, DRs project data from a high-dimensional space to a low-dimensional space. In essence, they are generalizations of the vector projection methods onto the x-, y-, and z-axes taught in a multivariable calculus course. DR is akin to conventional information compression, trading off size for information loss so choosing the best method and lower dimension is as much art as it is strategy.
Content I used this project to put fingers to keyboard and learn through implementation. I explored two avenues, applying
 PCA An autoencoder  to a waveform-to-cell type classification problem.
PCA is the OG DR method. It decomposes the covariance matrix of the dataset to discover components that explain the most variance of the dataset. Then, the dataset is projected onto these components, which often times could .
Autoencoders (AEs) are a deep neural network (DNN) that learns to encode examples in a dataset to a lower dimensional latent vector and then decode the latent vector back to the original example. Usually, AEs learn to project examples to a manifold, i.e., they are non-linear DR methods.
Essentially, this project compares linear vs. non-linear DR.
Method Dataset The dataset and article Sofroniew, Nicholas James et al. “Neural coding in barrel cortex during whisker-guided locomotion.” can be found on the author&amp;rsquo;s GitHub repo. Of the 16,000 recorded neurons, approx. 30 neurons were recorded for each of 13 subjects. Each recording was comprised of 53 voltage measurements. Overall, the dataset is composed of 302 waveforms. Unavoidably, the dataset is unbalanced; regular spikers comprise 247 of the examples while intermediate spikers only make up 4 examples.
 Figure 1. Summary of the waveforms with mean waveform (left) and waveform distributions by cell type (right). Note that the mean waveform is essentially the tightly bounded waveform distribution for regular spikers, which dominate the dataset.  Classification To compare and contrast the baseline, PCA, and autoencoding, I implemented a KNN classifier that uses Euclidean distance and majority vote for classification. To find the best number of neighbors given the dataset, I ran it through a standard hyperparameter search using cross-validation and a stratified split of the dataset to mitigate unbalanced classes. Once a good k-value was found, I evaluated the model on the test set, as well as a reclassification of the training set for debugging purposes.
Results The experiments for PCA and autoencoding had the same structure: 1. find the best reduced dimensionality, 2. reduce the dataset, and 3. test with KNN.
 Figure 2. Scree plot (left) and cumulative explained variance of the first N components (right) from PCA applied to the waveforms.   Table 1. Baseline results for a KNN fit on 53-dimensional waveform feature vectors.   Table 2. PCA results for a KNN fit on 3- dimensional waveform components.   Figure 3. 3D spatial distribution of the waveform principal components from PCA.   Table 3. Autoencoding results for a KNN fit on 3-dimensional waveform components.   Figure 4. 3D spatial distribution of the encodings from the bottleneck layer of the autoencoder.  For both PCA and autoencoding, the accuracy is only slightly worse than that of the baseline. For PCA, the test accuracy is exactly the same for the 3 seeds while for the autoencoder it is only slightly worse. On the other hand, for the debug accuracy, PCA performs worse than the baseline while the autoencoder performs better. Given that trend, it might suggest that the autoencoder is somewhat overfitting the dataset, diminishing its generalizability. However, the test accuracy suggests that it is not significantly detrimental. All in all, dimensionality reduction still yields data suitable for high performance, even with information loss.
Future PCA is a fixed method but AEs are newer and more flexible. A whole study could be done just exploring AE architectures that yield the best projection for this classification task, not to mention other relevant tasks. Of course, other non-DNN non-linear DR methods could be applied to this dataset, which would be particularly interesting for the classification of waveform to subject. Perhaps one of those methods or an AE would be able to adequately separate these classes, which were not easily separable by PCA when I tried.
 Figure 5. 3D spatial distribution of the waveform principal components from PCA for each subject. PCA could not separate these overlapping classes very well,.  References Cunningham, J., Yu, B. Dimensionality reduction for large-scale neural recordings. Nat Neurosci 17, 1500–1509 (2014). https://doi.org/10.1038/nn.3776
Paninski L, Cunningham JP. Neural data science: accelerating the experiment-analysis- theory cycle in large-scale neuroscience. Curr Opin Neurobiol. 2018 Jun;50:232-241. doi: 10.1016/j.conb.2018.04.007. PMID: 29738986.
Wu, Tong et al. “Deep Compressive Autoencoder for Action Potential Compression in Large-Scale Neural Recording.” Journal of Neural Engineering 15.6 (2018): n. pag. Journal of Neural Engineering. Web.
Ladjal, Saïd, Alasdair Newson, and Chi Hieu Pham. “A PCA-like Autoencoder.” arXiv 2 Apr. 2019: n. pag. Print.
Scree and cumulative explained variance plots
Matplotlib 3D scatter plot
Keras autoencoder guide
Hyperparameter grid search for Keras:
 https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/ https://stackoverflow.com/questions/49823192/autoencoder-gridsearch-hyperparameter-tuning-keras https://towardsdatascience.com/autoencoders-for-the-compression-of-stock-market-data-28e8c1a2da3e  ]]></content:encoded>
    </item>
  </channel>
</rss>
