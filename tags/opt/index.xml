<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <docs>https://blogs.law.harvard.edu/tech/rss</docs>
    <title>Opt on Zach Stoebner | ECE PhD @ UT Austin</title>
    <link>//localhost:1313/tags/opt/</link>
    <description>Recent content in Opt on Zach Stoebner | ECE PhD @ UT Austin</description>
    <image>
      <title>Opt on Zach Stoebner | ECE PhD @ UT Austin</title>
      <link>//localhost:1313/tags/opt/</link>
      <url>https://source.unsplash.com/collection/983219/2000x1322</url>
    </image>
    <ttl>1440</ttl>
    <generator>After Dark 9.2.3 (Hugo 0.152.2)</generator>
    <language>en-US</language>
    <copyright>Copyright &copy; Zachary Stoebner. Licensed under CC-BY-ND-4.0.</copyright>
    <lastBuildDate>Thu, 26 Feb 2026 22:40:42 UT</lastBuildDate>
    <atom:link href="//localhost:1313/tags/opt/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>on Lipschitzness, monotonicity, and cocoercivity</title>
      <link>//localhost:1313/notes/lip-mon-coc/</link>
      <pubDate>Thu, 26 Feb 2026 22:17:45 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>//localhost:1313/notes/lip-mon-coc/</guid>
      <description>Lipschitzness, monotonocity, and cocoercivity are prominent operator properties involved in an algorithm&rsquo;s behavior, but their relationship to each other and what they intuitively mean about an operator and its geometry is typically overlooked and complicated in the literature. To develop intuition, this note explores what they mean and how they connect.</description>
      <content:encoded><![CDATA[ Open PDF
]]></content:encoded>
    </item>
    <item>
      <title>on univariate Chebyshev approximation</title>
      <link>//localhost:1313/notes/chebyshev-approx/</link>
      <pubDate>Sun, 21 Dec 2025 13:13:58 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>//localhost:1313/notes/chebyshev-approx/</guid>
      <description>Chebyshev polynomials of the first kind are a popular choice of basis polynomials for function approximation. Here, this note collects some properties and theorems for approximating univariate functions, with an example.</description>
      <content:encoded><![CDATA[ Open PDF
]]></content:encoded>
    </item>
    <item>
      <title>on preconditioning for iterative optimization</title>
      <link>//localhost:1313/notes/precon/</link>
      <pubDate>Sat, 03 May 2025 20:49:00 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>//localhost:1313/notes/precon/</guid>
      <description>Preconditioning adjusts the state of a model to {expedite, improve, stabilize} convergence of an optimization procedure, typically by adjusting the gradient in the update rule with the inverse of the Hessian or improving the condition number of a matrix whose spectrum affects convergence.</description>
      <content:encoded><![CDATA[Preconditioning adjusts the state of a model to {expedite, improve, stabilize} convergence of an optimization procedure, typically by adjusting the gradient in the update rule with the inverse of the Hessian or improving the condition number of a matrix whose spectrum affects convergence. For the following problems, we are solving $\min_x \frac{1}{2}||Ax-b||_2^2$ for positive definite $A$ where $\kappa (A)$ is large.
Newton method This is a root-finding method for a convex function based on its linear approximation (first-order definition of convexity):
A function is convex if $\forall x,y \in D(f)$:
$$ f(y) \leq f(x) + \partial f(x)^T (y-x) $$which implies every tangent line of $f$ is below the function. Therefore, if the tangent line intercepts the domain at $y$ then:
$$ \partial f(x) = \frac{f(x) - 0}{x - y} \implies y = x - (\partial f(x))^{-1} f(x) $$Rewriting this as an iterative scheme:
$$ x_{n+1} = x_n - (\partial f(x_n))^{-1} f(x_n) $$In the context of finding minima with gradient descent (assuming f is twice differentiable), the Newton update is:
$$ x_{n+1} = x_n - (\partial^2 f(x_n))^{-1} \partial f(x_n) $$Note that for differentiable scalar-valued functions $f: \mathbb{R}^n \rightarrow \mathbb{R} \implies \partial f(x) = \nabla f(x)$ (the subdifferential equals the gradient) and for vector-valued functions $f: \mathbb{R}^n \rightarrow \mathbb{R}^m \implies \partial f(x) = J_f (x)$ (the subdifferential equals the Jacobian).
Figure 1. Convergence of Newton's method vs gradient descent on different plots. Newton's method convergences more quickly and closely to the solution than gradient descent when the problem is poorly conditioned. Quasi-Newton method For multivariate, high-dimensional regimes, computing the Hessian, Jacobian, etc. can be expensive $\mathcal{O} (mn)$, which implies its an order higher to compute the inverse $\mathcal{O} (n^3)$. Quasi-Newton methods accelerate this procedure with iterative updates to an approximation of the inverse Hessian and one of the most renowned is the BFGS method &ndash; named after Broyden, Fletcher, Goldfarb, and Shanno &ndash; which is implemented in this example.
How do we derive a good approximate of the Hessian?
Similar to Newton&rsquo;s method, we start from the second-order approximation of a convex function:
$$ f(y) \leq f(x) + \partial f(x)^T (y-x) + \frac{1}{2} (y-x)^T B (y-x) $$If $y=x_k + \Delta x$ and we take the gradient w.r.t. $\Delta x$, we get the secant equation:
$$ \partial f(x_k + \Delta x) \leq \partial f(x_k) + B \Delta x $$If we set it to 0: $$ \Delta x = -B^{-1} \partial f(x_k) $$which implies the Newton step so this is consistent if B is the Hessian.
The secant equation is a line in the function&rsquo;s gradient space that can be used as a condition for each update of the Hessian. How this secant equation is solved is what sets different quasi-Newton methods apart. In BFGS, the quasi-Newton condition is:
$$ B_{k+1} (x_{k+1} - x_k) = \nabla f(x_{k+1}) - \nabla f(x_k) $$First, we set $B_0 = \beta I$ where $\beta > 0$ is hyperparameter ensuring that we start with a positive-definite matrix and choose step size $\alpha_k$ with an exact line search adhering to the Wolfe conditions which are:
$$ \begin{align} f(x_k + \alpha_k p_k) &\leq f(x_k) + c_1 \alpha_k p_k^T \nabla f(x_k) \\\ p_k^T \nabla f(x_k + \alpha_k p_k) &\geq c_2 p_k^T \nabla f(x_k) \end{align} $$Then our update rule is:
$$ x_{k+1} = x_k - \alpha_k B^{-1}_k \partial f(x_k) $$Using only the known terms in the current update and the gradient at the new iterate $\partial f(x_{k+1})$, we can update the Hessian $B_k$ with Broyden&rsquo;s method or directly update the inverse Hessian $B_k^{-1}$ with the Sherman-Morrison formula.
The algorithm steps are as follows:
Obtain direction $p_k = -B^{-1}_k \nabla f(x_k)$ Perform a line search on $\alpha_k$ until the Wolfe conditions on the current iterates are satisfied Set $s_k = \alpha_k p_k$, $x_{k+1} = x_k + s_k$, and $y_k = \nabla f(x_{k+1}) - \nabla f(x_k)$ Update inverse Hessian approximation with the SM formula. Let $H_k = B^{-1}_k, \rho = s_K^T y_k$, then: $$ H_{k+1} = H_k + \frac{(\rho + y_k^T H_k y_k)(s_k s_k^T)}{\rho^2} - \frac{H_k y_k s_k^T + s_k y_k^T H_k}{\rho} $$Note that an approximation of theoretic preconditioners does change the geometry of the problem so the true optimum is technically different. The idea is to ensure an good approximation that makes the change negligible.
Figure 2. Convergence of Newton's method vs gradient descent on different plots. Newton's method convergences more quickly to the solution than gradient descent or BFGS but BFGS converges substantially better and faster than gradient descent when the problem is poorly conditioned. Conjugate Gradient Conjugate gradient (CG) minimizes the quadratic:
$$ f(x) = b^T x - \frac{1}{2} x^T A x $$where $A$ is positive definite.
Note that the residual norm $||b-Ax||$ is not necessarily monotonically decreasing since $||b-Ax||^2 = x^T A^T A x - 2 b^T Ax + b^T b$ differs from the objective.
If $x \in \mathbb{R}^n$ then CG takes at most $n$ iterations to converge by updating $x_k$ along directions $p_k$ which are conjugate w.r.t. $A$. That is:
$$ x_{k+1} = x_k + \alpha_k p_k $$where $p_i^T A p_j = 0$ for $i \neq j$. This implies that $\\{p_1, ..., p_n\\}$ for a basis for $\mathbb{R}^n$ so we can express $ x^* $ as a linear combination of the conjugate directions, i.e., $x^* = \sum_{i=1}^n \alpha_i p_i$ which is equivalent to taking n steps along orthogonal conjugate directions. We can solve for the exact $\alpha_k$ assuming we have access to all $p_k$. However, for large $A$, finding n conjugate directions is intractable.
An important result for iteratively computing $\alpha_k$ and $p_k$ for CG is that the Krylov sequence induced by $A$ implies that $span \\{r_0,...,r_k \\} = span\\{r_0,...,A^k r_0\\} = span\\{p_0,...,p_k\\} \subset span\\{p_0,...,p_k,...,p_n\\}$ where $r_k = \nabla f(x_k) = b - Ax_k$. Therefore, $\alpha_k$ and $p_k$ can be written in terms of the residual $r_k$ at each iteration. Then the update rules are:
$$ \begin{align} p_0 &= r_0 = b \\\ \alpha_k &= \frac{r_k^T r_k}{p_k^T A p_k} \\\ r_{k+1} &= r_k - \alpha_k A p_k \\\ p_{k+1} &= r_k + \frac{r_{k+1}^T r_{k+1}}{r_k^T r_k} p_k \end{align} $$Take a look at Boyd&rsquo;s notes on CG for more explanation.
Preconditioned CG The convergence of iterative methods depends on the spectral properties of the system matrix $A$. If $A$ is poorly conditioned, then method will take longer to converge. The condition number for any matrix $A$ is defined as:
$$ \begin{align} \kappa(A) &= ||A|| \\\ ||A^{-1}|| &= \frac{\sigma_{max}(A)}{\sigma_{min}(A)} \end{align} $$Therefore, $\kappa(A) \geq 1$ where $\kappa(A) = 1$ is the best conditioning. To precondition CG, we want to find a matrix $M$ s.t. $M^{-1} A \approx 1$ or at least $\kappa(M^{-1} A) < \kappa(A)$.
Designing $M$ depends on $A$. If $A$ is diagonal or diagonally dominant, then a simple Jacobi preconditioner typically suffices. A more robust method is using incomplete Cholesky factorization to tractably design a matrix from lower trianglular matrices that improves the problem&rsquo;s conditioning or using Chebyshev polynomials.
With the preconditioner, we want to solve the equivalent system:
$$ \hat{A} \hat{x} = \hat{b} \text{ where } M=LL^T, \hat{A} = L^{-1} A L^{-T}, \hat{x} = L^T x, \hat{b} = L^{-1} b $$This results in an extra step of finding $z_k$ s.t. $M z_k = r_k$, which adjusts the updates:
$$ \begin{align} \alpha_k &= \frac{r_k^T z_k}{p_k^T A p_k} \\\ p_{k+1} &= r_k + \frac{r_{k+1}^T z_{k+1}}{r_k^T z_k} p_k \end{align} $$Here are some good notes on preconditioning CG.
Figure 3. Convergence of vanilla conjugate gradient vs preconditioned conjugate gradient. Preconditioning leads to iterates that are closer to the solution. For high-dimensional problems where $n$ is very large, preconditioning is necessary to approximate a close-enough solution in a reasonable amount of time. ]]></content:encoded>
    </item>
    <item>
      <title>exploring compressed sensing fMRI time series</title>
      <link>//localhost:1313/notes/csfmri-ts/</link>
      <pubDate>Tue, 31 May 2022 18:26:14 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>//localhost:1313/notes/csfmri-ts/</guid>
      <description>An exploration of compressed sensing fMRI time series with 3 different algorithms. Typically, compressed sensing reconstructs a single volume of MRI but fMRI are composed of many volumes; sensing along the time domain could reduce the number of volumes required. Of the 3 algorithms, BSBL-BO performed the best with the error curve elbowing around 30% subsampling.</description>
      <category domain="//localhost:1313/categories/course">Course</category>
      <category domain="//localhost:1313/categories/solo">Solo</category>
      <content:encoded><![CDATA[ Signal sensing at 30% undersampling using the BSBL-BO algorithm. `$Y_i$` corresponds to time-domain signals whereas `$x_i$` corresponds to frequency-domain signals. tl;dr An exploration of compressed sensing fMRI time series with 3 different algorithms. Typically, compressed sensing reconstructs a single volume of MRI but fMRI are composed of many volumes; sensing along the time domain could reduce the number of volumes required. Of the 3 algorithms, BSBL-BO performed the best with the error curve elbowing around 30% subsampling.
Links repo
report
Abstract Compressed sensing reconstructs signals by solving underdetermined linear systems under the con- ditions that the measurements are sparse in the domain and incoherent [1]. In engineering, if measurements are taken within an appropriate basis satisfying the restricted isometry property, i.e., the Gaussian, Bernoulli, or Fourier bases, then this prior structure makes full signal recovery possible [2].
Compressed sensing is challenging with fMRI because the temporal dynamics of hemodynamic signals are relatively slow compared to other fast-acquisition signals that historically benefit from compressed sensing [3]. Additionally, having fewer samples insinuates a loss of statistical power in subsequent analyses. Thankfully, fMRI signals boast two beneficial characteristics that are promising for compressed sensing: 1. they are linear time-invariant, and 2. they lie within, and can transformed by, a Fourier basis [4].
In medical imaging, it is often assumed that an image is sampled at the Nyquist rate, s.t., enough discrete measurements are taken to reconstruct a continuous whole (M &gt; N) without loss of information. If high-fidelity reconstruction is possible sampling below the Nyquist rate, then MRI modalities would benefit since discerning a signal and quickly turning over an analysis reduces real costs. These potential gains beg the question: if an underdetermined linear system can be solved after sampling below the Nyquist rate, can we collect fewer samples and still recover a high-quality fMRI under a compressed sensing paradigm? The purpose of this project is to explore approaches to compressed sensing that yield meaningful signal recoveries from heavy undersampling.
Results Summary metrics of RMSE (left) and PSNR (right) voxel time series recovery using L1 minimization in a pure convex optimization formulation solved with the ECOS algorithm. Summary metrics of RMSE (left) and PSNR (right) voxel time series recovery using L1 minimization in a pure convex optimization formulation solved with the OWL-QN algorithm. Summary metrics of RMSE (left) and PSNR (right) voxel time series recovery using L1 minimization in a pure convex optimization formulation solved with the BSBL-BO algorithm. References [1] E. J. Candes et al., “Compressive sampling,” in Proceedings of the international congress of mathematicians, vol. 3, pp. 1433–1452, Citeseer, 2006.
[2] D. Angelosante, G. B. Giannakis, and E. Grossi, “Compressed sensing of time-varying signals,” in 2009 16th International Conference on Digital Signal Processing, pp. 1–8, IEEE, 2009.
[3] X. Zong, J. Lee, A. J. Poplawsky, S.-G. Kim, and J. C. Ye, “Compressed sensing fmri using gradient-recalled echo and epi sequences,” NeuroImage, vol. 92, pp. 312–321, 2014.
[4] O. Jeromin, M. S. Pattichis, and V. D. Calhoun, “Optimal compressed sensing reconstructions of fmri using 2d deterministic and stochastic sampling geometries,” Biomedical engineering online, vol. 11, no. 1, pp. 1–36, 2012.
[5] A. Domahidi, E. Chu, and S. Boyd, “ECOS: An SOCP solver for embedded systems,” in European Control Conference (ECC), pp. 3071–3076, 2013.
[6] G. Andrew and J. Gao, “Scalable training of l 1-regularized log-linear models,” in Proceedings of the 24th international conference on Machine learning, pp. 33–40, 2007.
[7] Z. Zhang and B. D. Rao, “Extension of sbl algorithms for the recovery of block sparse signals with intra-block correlation,” IEEE Transactions on Signal Processing, vol. 61, no. 8, pp. 2009– 2015, 2013.
[8] P. Wolfe, “Convergence conditions for ascent methods,” SIAM Review, vol. 11, no. 2, pp. 226– 235, 1969.
[9] H. Park and X. Liu, “Study on compressed sensing of action potential,” arXiv preprint arXiv:2102.00284, 2021.
[10] A. Jalal, M. Arvinte, G. Daras, E. Price, A. G. Dimakis, and J. Tamir, “Robust compressed sensing mri with deep generative priors,” Advances in Neural Information Processing Systems, vol. 34, pp. 14938–14954, 2021.
[11] X. Li, T. Cao, Y. Tong, X. Ma, Z. Niu, and H. Guo, “Deep residual network for highly accel- erated fmri reconstruction using variable density spiral trajectory,” Neurocomputing, vol. 398, pp. 338–346, 2020.
]]></content:encoded>
    </item>
    <item>
      <title>autonomous motion planning for an NVIDIA JetBot</title>
      <link>//localhost:1313/notes/jetbot-motion-planning/</link>
      <pubDate>Thu, 09 Dec 2021 01:05:08 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>//localhost:1313/notes/jetbot-motion-planning/</guid>
      <description>Built a JetBot + an exploration and novice implementation of motion planning on said JetBot. This computational game theory project marked my first foray into optimization and a glimpse of its power muahahaha. It ain&rsquo;t exquisite but it was heading in the right direction.</description>
      <category domain="//localhost:1313/categories/course">Course</category>
      <category domain="//localhost:1313/categories/solo">Solo</category>
      <content:encoded><![CDATA[ tl;dr Built a JetBot + an exploration and novice implementation of motion planning on said JetBot. This computational game theory project marked my first foray into optimization and a glimpse of its power muahahaha. It ain&rsquo;t exquisite but it was heading in the right direction.
Links repo
report
Background Although autonomous vehicles are the talk of the town these days, the methodologies behind them are elusive to most. To help yourself, I suggest reading my note on LCPs and then follow that up with section 3.1 of this thesis on LMCPs and the path solver for MCPs.
Path planning in autonomous vehicles is a booming research area with significant developments. Although computer vision and machine learning are often employed to plan motion in autonomous vehicles, computationally solving the optimization problems, that arise from in scenarios of motion planning, through a game theoretic is a lightweight alternative to path solving. In this scenario, the path planning optimization problem is formulated as a nonlinear complementarity problem (NCP) constrained by physics and simple car dynamics, which cannot necessarily be directly and exactly solved. Instead the NCP can be approximated by linear mixed complementarity problems (LMCPs), iteratively computing partial paths that together approximate the solution to the NCP and yield a motion planned trajectory for an autonomous vehicle.
The problem formulation is a non-visual scenario where stationary obstacles are laid out on a grid, in a predetermined fashion, and an optimal path must be computed through these obstacles to some goal point without exceeding bounds. Such paths are often nonlinear and can be closely approximated by solving linear mixed complementarity problems via a pathsolver algorithm. Once the path is determined, the JetBot must then move in a real setting, of which the software representation of the grid space is a projection.
Building the JetBot The JetBot was built following the documentation on the JetBot homepage. For the parts with multiple options: the IMX219-160 listed as the second option for cameras, the M2 card + antennas listed as the first option for wifi, and the 65mm wheels listed as the second option for wheels were used. The total cost was approximately $300. The hardware setup time was approximately twelve hours spread between two days. A significant portion of the time was spent extracting a screw terminal from the motor board that was placed incorrectly. 1 shows the completed JetBot hardware assembly.
Motion Path Solver This notebook contains code for non-visual motion planning – the primary objective of the project. The code relies on an LMCP solver that takes an LMCP formulation in M, q, l, u, x 0 and returns a path of points of z, w, v, t. A pathsolver then iteratively solves LMCPs for Newton points along an overarching path, performing backward linesearch to progress sufficiently down each of these paths towards the predefined goal point.
Solving many LMCPs approximates a nonlinear path, which can be formulated as an NMCP for which the KKT conditions must first be derived. The KKT conditions are formulated symbolically so that KKT function as well as the Jacobian of the KKT can be passed to the pathsolver for sparse JIT evaluation, accelerating runtime. Once the point sequence is acquired, it is passed to a module for JetBot motion planning to attempt to move the JetBot along the equivalent trajectory on a real grid space.
Motion Algorithms To achieve the best motion possible on the JetBot, various motion planning algorithms were implemented: linear approximation, Manhattan (aka wiggle) motion, and proportional / integrative / derivative (PID) control. For some of these algorithms, the arctan2 function is used to compute the angle for turning from one orientation to another. (The full code for the JetBotMotion class is included in the appendix.)
arctan 2(∆y, ∆x)
The approximate relevant specifications measured for the JetBot were:
With two obstacles, sometimes the pathsolver fails if dt is too small =⇒ dt &gt; 0.1
Confirmed that the solved states [x, y, v x , v y ] closely approximate the dynamics of horizontal motion
JetBot moves forward 40cm in 0.75 sec at speed=1
JetBot rotates 360 degrees in 1 sec at speed=1
Results Figure 1. Fully assembled JetBot. The two views show the camera, ports, wheels, and overall build structure of the JetBot. In the background is the soldering iron used during assembly. Figure 2. JetBot movement sequence for { (1, 1), (1, 0), (−1, 0), (−1, −1), (0, 1) } . Blue arrows indicate scene flow. The yellow arrow indicates the point that the JetBot should go to next; the yellow circle indicates the final location. Figure 3. Attempted JetBot linear approximation movement on a single obstacle course. The bottom left pane is the predicted trajectory from the pathsolver. Blue arrows indicate scene flow. The yellow arrow indicates the point that the JetBot should go to next; the yellow circle indicates the final location. Figure 4. Attempted JetBot linear approximation movement on a double obstacle course. The bottom left pane is the predicted trajectory from the pathsolver. Blue arrows indicate scene flow. The yellow arrow indicates the point that the JetBot should go to next; the yellow circle indicates the final location. Figure 5. Attempted JetBot Manhattan movement on a double obstacle course. The bottom left pane is the predicted trajectory from the pathsolver. Blue arrows indicate scene flow. The yellow arrow indicates the point that the JetBot should go to next; the yellow circle indicates the final location. Figure 6. Attempted JetBot PID control movement on a double obstacle course. The middle pane is the predicted trajectory from the pathsolver. Blue arrows indicate scene flow. The yellow arrow indicates the point that the JetBot should go to next; the yellow circle indicates the final location. This method resulted in a more correct, but still erroneous, path realization. References Enzenhofer. &ldquo;Numerical Solution of Mixed Linear Complementarity Problems in Multibody Dynamics with Contact.&rdquo; 2018
Dirkse, Steven &amp; Ferris, Michael. (1995). The path solver: a nommonotone stabilization scheme for mixed complementarity problems. Optimization Methods &amp; Software - OPTIM METHOD SOFTW. 5. 123-156. 10.1080/10556789508805606.
[1] Pepy, R., Lambert, A., and Mounier, H., “Path planning using a dynamic vehicle model,” in [2006 2nd International Conference on Information Communication Technologies], 1, 781–786 (2006). [2] Choset, H., La Civita, M., and Park, J., “Path planning between two points for a robot experiencing local- ization error in known and unknown environments,” (11 1999). [3] Lozano-Perez, T., “A simple motion-planning algorithm for general robot manipulators,” IEEE Journal on Robotics and Automation 3(3), 224–238 (1987). [4] Yonetani, R., Taniai, T., Barekatain, M., Nishimura, M., and Kanezaki, A., “Path planning using neural a* search,” in [International Conference on Machine Learning], 12029–12039, PMLR (2021). [5] Lee, L., Parisotto, E., Chaplot, D. S., Xing, E., and Salakhutdinov, R., “Gated path planning networks,” in [International Conference on Machine Learning], 2947–2955, PMLR (2018). [6] Mansouri, S. S., Kanellakis, C., Fresk, E., Kominiak, D., and Nikolakopoulos, G., “Cooperative coverage path planning for visual inspection,” Control Engineering Practice 74, 118–131 (2018). [7] Dirkse, S. and Ferris, M., “The path solver: A non-monotone stabilization scheme for mixed complementarity problems,” Optimization Methods and Software 5 (12 1993). [8] Andersson, J. A. E., Gillis, J., Horn, G., Rawlings, J. B., and Diehl, M., “CasADi – A software framework for nonlinear optimization and optimal control,” Mathematical Programming Computation (In Press, 2018). [9] Araki, M., “Pid control,” CONTROL SYSTEMS, ROBOTICS, AND AUTOMATION 2.
]]></content:encoded>
    </item>
    <item>
      <title>on linear complementarity problems</title>
      <link>//localhost:1313/notes/lcp/</link>
      <pubDate>Wed, 24 Nov 2021 17:06:11 UT</pubDate>
      <dc:creator>Zach Stoebner</dc:creator>
      <guid>//localhost:1313/notes/lcp/</guid>
      <description>This Fall 2021, I am taking a course on computational game theory, which insofar is the formulation of various games (e.g. bimatrix, Stackelberg) as mathematical programs and the algorithms that solve them, or approximate solutions. Linear complementarity problems are foundational for computing Nash equilibria of simple games.</description>
      <category domain="//localhost:1313/categories/algo">Algo</category>
      <content:encoded><![CDATA[tl;dr This Fall 2021, I am taking a course on computational game theory, which insofar is the formulation of various games (e.g. bimatrix, Stackelberg) as mathematical programs and the algorithms that solve them, or approximate solutions. Linear complementarity problems are foundational for computing Nash equilibria of simple games.
Background Programming A mathematical program is an optimization (min, max) over an objective function and constraints. A linear program (LP) is one where the objective function and the constraints are all linear.
The general LP formulation. Aside: The terms &lsquo;argmin&rsquo; and &lsquo;argmax&rsquo; are special terminology for returning the optimizing value of the argument, instead of the optimal value of the function.
Complementarity A complementarity condition is a special kind of constraint required for solving linear complementarity problems (LCPs), as the name suggests. The non-negative vectors x and y are complements if one or both of the values at corresponding indices are 0.
The definition of complementarity. Complementarity results from a program&rsquo;s transformation into an LCP. Generally, it is not a constraint defined in the programs of the game.
Games &amp; Equilibria Intuitively, games are multiple programs that relate to each other. An equilibrium is a simultaneous joint solution that solves all optimization problems in a game.
In Nash games, it is assumed that the opponent will always play their optimal move, so the player should always play their optimal move. A Nash equilibrium is a best player&rsquo;s best move without deviating from their predefined strategy, i.e., a matrix of costs for each of the player&rsquo;s moves against each of the opponent&rsquo;s moves. Solving Nash games is the same as finding the Nash equilibria.
Aside: John Nash proved that in every finite game all players can arrive at an optimal outcome.
Linear Complementarity Problem An LCP is defined as:
The general form of an LCP. LCPs are important and useful, for both mathematical and computer, programming because they can be analytically and algorithmically solved. Therefore, any programs that can be transformed into an LCP can be solved through the LCP; for Nash games, solutions to the LCP are thus the Nash equilibria.
Karush-Kuhn-Tucker Conditions The Karush-Kuhn-Tucker (KKT) conditions are a set of first-order conditions using a program&rsquo;s objective function and constraints that must be satisfied by any optima. For the general form of a program:
The general form of a mathematical program. The KKT conditions are defined as:
The KKT conditions for a general program. The KKT conditions of the programs in a Nash game can be composed into an LCP. Solutions to the LCP satisfy the KKT conditions and are therefore Nash equilibria and solutions to the game.
For the linear program above, the KKT conditions are:
The KKT conditions for a linear program. which can then be composed into a function of the following form:
The KKT conditions as a function for an LCP. Complementarity conditions can then be enforced over this function of KKT conditions to form an LCP. Voilà!
Other programs, e.g., quadratic programs (QPs), can also be massaged into LCPs by stacking their KKT conditions in this way. Some problems can be massaged into complementarity problems, but not necessarily LCPs. Amusingly, the solutions to those problems are often approximated by solving LCPs.
Lemke&rsquo;s Method Lemke&rsquo;s method is a pivoting algorithm for computationally finding solutions to LCPs. The rearranged equation above can be organized into a tableau of the form:
The tableau to solve the LCP via Lemke's method. You may already see that essentially finding solutions to the LCP is solving a system of equations. However, since the tableau is a wide matrix, the system is underdetermined so there are infinitely many solutions, i.e., they lie in a conic region defined by complementary pairs of columns in the tableau, or no solutions, i.e., if q is not contained in any complementary cone.
For n variables in the z vector, there are necessarily 2n columns in the tableau with the n slack variables for w. Because of the stacked KKT conditions in the function, there are n rows. This suggests that any n of the variables, defined by their corresponding columns, can form a basis B to define the conic region containing a feasible solution. The decomposition of the system into basis and non-basis parts:
The decomposition of an undetermined system into basis and non-basis components. Since B is a basis of linearly independent columns, it can be inverted and the basis variables can technically determined that way. However, these matrices can be enormous in practice and inverting a matrix is very computationally expensive. Thankfully, iteratively pivoting the tableau is one way to accomplish the same goal without ever needing to invert a giant matrix. The high-level steps are:
Use a minimum ratio test to determine the exiting variable from the basis. Row-reduce the tableau along the pivot column that corresponds to the entering variable at the row index of the exiting variable s.t. the pivot column is now one-hot at that row index. Replace the exiting variable with the entering variable at its index in the basis vector. The next entering variable is the complementary variable to the exiting variable, i.e., w_i -&gt; z_i. Stop conditions for the algorithm typically include: the values in the pivot columns are out of bounds, i.e., z_i &lt; 0, or the initial entering variable z_0 leaves the basis. At the end of the algorithm, the values in the column corresponding to q will be the values of the basis variables in the final basis, and their complements will be 0. There are a number of modifications and tricks on top of this basic scaffolding that have been developed to handle variant complementarity problems. For discussion of each variant of Lemke&rsquo;s method and their implementation details, I suggest reading Chapter 2 of the Murty textbook.
Other Complementarity Problems &amp; Applications LCPs are in fact a very specific formulation of complementarity problems and generalizations exist, e.g., nonlinear (NCP), linear mixed (LMCP), and mixed (MCP) complementarity problems, which have looser constraints than an LCP. However, these problems typically cannot be analytically solved like LCPs, but can be approximated by LCPs.
Solving games underlies many practical applications, ranging from hot topics, such as autonomous driving and reinforcement learning, to age-old games, i.e., tag, motion planning, i.e., approximating MCPs with the PATH solver, and physics simulations.
A simulation of a tag game. Converting a QP to an LCP and solving via Lemke's method are the crux of generating trajectories for each agent to optimally play the game. References Murty. &ldquo;LINEAR COMPLEMENTARITY, LINEAR AND NONLINEAR PROGRAMMING.&rdquo; 1997.
Cottle, Pang, Stone. &ldquo;The Linear Complementarity Problem.&rdquo; 2008
Dirkse, Steven &amp; Ferris, Michael. (1995). The path solver: a nommonotone stabilization scheme for mixed complementarity problems. Optimization Methods &amp; Software - OPTIM METHOD SOFTW. 5. 123-156. 10.1080/10556789508805606.
GAMS PATH Solver
Nisan et al. &ldquo;Algorithmic Game Theory.&rdquo; 2007
Enzenhofer. &ldquo;Numerical Solution of Mixed Linear Complementarity Problems in Multibody Dynamics with Contact.&rdquo; 2018
Nocedal &amp; Wright. &ldquo;Numerical Optimization.&rdquo; 2006.
Ralph. &ldquo;Global Convergence of Damped Newton&rsquo;s Method for Nonsmooth Equations via the Path Search.&rdquo; 1990.
]]></content:encoded>
    </item>
  </channel>
</rss>
